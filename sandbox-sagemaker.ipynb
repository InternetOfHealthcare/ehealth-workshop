{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "import datetime \n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "time_fmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "hours = 24 * 30\n",
    "date = datetime.datetime(2017, 1, 1, 8, 0)\n",
    "data_file = \"deepar_training.json\"\n",
    "fh = open(data_file, \"w\")\n",
    "data = []\n",
    "bp_sistolic = []\n",
    "bp_diastolic = []\n",
    "bp_time = date\n",
    "for m in range(0,hours):\n",
    "    noise  = round(40 * random.random())\n",
    "    bp_sistolic.append(110+noise)\n",
    "    bp_diastolic.append(70+noise)\n",
    "sistolic = {\"start\": bp_time.strftime(time_fmt), \"target\": bp_sistolic, \"cat\": 0}\n",
    "sistolic = json.dumps(sistolic) \n",
    "diastolic = {\"start\": bp_time.strftime(time_fmt), \"target\": bp_diastolic, \"cat\": 1}\n",
    "diastolic = json.dumps(diastolic) \n",
    "print(sistolic,file=fh)\n",
    "print(diastolic,file=fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l \"{data_file}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp \"{data_file}\" \"{test_file}\"\n",
    "!open \"{data_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "uuid = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket         = 'bpdata_'+uuid\n",
    "prefix         = 'sagemaker'\n",
    "region = \"us-east-1\" \n",
    "train_key      = 'deepar_training.json'\n",
    "test_key       = 'deepar_test.json'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = '{}/{}'.format(prefix, 'output')\n",
    "output_path = 's3://{}/{}'.format(bucket, output_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket: bpdata_d4d38b6c-f257-4d83-9881-fe88b8f98a7c\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mb s3://{bucket}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path  = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path   = sagemaker_session.upload_data(test_key,  bucket=bucket, key_prefix=test_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-04 01:14:16      13458 deepar_training.json\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls  s3://{bucket}/sagemaker/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:latest'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containers = {\n",
    "    'us-east-1': '522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:latest',\n",
    "    'us-east-2': '566113047672.dkr.ecr.us-east-2.amazonaws.com/forecasting-deepar:latest',\n",
    "    'us-west-2': '156387875391.dkr.ecr.us-west-2.amazonaws.com/forecasting-deepar:latest',\n",
    "    'eu-west-1': '224300973850.dkr.ecr.eu-west-1.amazonaws.com/forecasting-deepar:latest'\n",
    "}\n",
    "\n",
    "image_name = containers[region]\n",
    "image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "role = \"arn:aws:iam::030555009967:role/service-role/AmazonSageMaker-ExecutionRole-20180107T101850\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.8xlarge',\n",
    "    base_job_name='bp-job',\n",
    "    output_path=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.estimator.Estimator at 0x115202048>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 24\n",
    "hyperparameters = {\n",
    "    \"time_freq\": 'H',\n",
    "    \"context_length\": prediction_length,\n",
    "    \"prediction_length\": prediction_length, # number of data points to predict\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"2\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"250\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.00001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\" # stop if loss hasn't improved in 10 epochs\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bpdata_d4d38b6c-f257-4d83-9881-fe88b8f98a7c/sagemaker/train/deepar_training.json\n",
      "s3://bpdata_d4d38b6c-f257-4d83-9881-fe88b8f98a7c/sagemaker/test/deepar_test.json\n",
      "s3://bpdata_d4d38b6c-f257-4d83-9881-fe88b8f98a7c/sagemaker/output\n"
     ]
    }
   ],
   "source": [
    "print(train_path)\n",
    "print(test_path)\n",
    "print(output_path)\n",
    "\n",
    "data_channels = {\"train\": train_path, \"test\": test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: bp-job-2018-02-04-00-14-40-208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:31 INFO 140150847625024] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'dropout_rate': u'0.05', u'cardinality': u'', u'test_quantiles': u'[0.5, 0.9]', u'_num_gpus': u'auto', u'learning_rate': u'0.001', u'_kvstore': u'auto', u'num_layers': u'3', u'embedding_dimension': u'', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:31 INFO 140150847625024] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'dropout_rate': u'0.05', u'learning_rate': u'0.00001', u'num_cells': u'40', u'prediction_length': u'24', u'epochs': u'250', u'time_freq': u'H', u'context_length': u'24', u'num_layers': u'2', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:31 INFO 140150847625024] Final configuration: {u'dropout_rate': u'0.05', u'test_quantiles': u'[0.5, 0.9]', u'learning_rate': u'0.00001', u'num_cells': u'40', u'epochs': u'250', u'embedding_dimension': u'', u'num_layers': u'2', u'_num_kv_servers': u'auto', u'cardinality': u'', u'likelihood': u'gaussian', u'mini_batch_size': u'32', u'_num_gpus': u'auto', u'prediction_length': u'24', u'time_freq': u'H', u'context_length': u'24', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:31 INFO 140150847625024] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] nvidia-smi took: 0.0251591205597 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Calculating training set statistics\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 WARNING 140150847625024] Dataset contains very few time-series which may not be sufficient for good accuracy\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Training set statistics:\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Integer timeseries\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] number of timeseries: 2\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] number of observations: 2880\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] mean target length: 1440\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] min/mean/max target: 70.0/110.331943512/150.0\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Small number of time-series. Doing 10 number of passes over dataset per epoch.\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Calculating training set statistics\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Test set statistics:\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Integer timeseries\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] number of timeseries: 2\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] number of observations: 2880\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] mean target length: 1440\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] min/mean/max target: 70.0/110.331943512/150.0\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Create Store: local\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 90.36111831665039, \"sum\": 90.36111831665039, \"min\": 90.36111831665039}}, \"EndTime\": 1517703633.853642, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703633.762534}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 208.59503746032715, \"sum\": 208.59503746032715, \"min\": 208.59503746032715}}, \"EndTime\": 1517703633.971179, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703633.853704}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:33 INFO 140150847625024] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:34 INFO 140150847625024] Epoch[0] Batch[0] avg_epoch_loss=7.585669\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:34 INFO 140150847625024] Epoch[0] Batch[5] avg_epoch_loss=7.594587\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:34 INFO 140150847625024] Epoch[0] Batch [5]#011Speed: 317.11 samples/sec#011loss=7.594587\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] Epoch[0] Batch[10] avg_epoch_loss=7.559391\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] Epoch[0] Batch [10]#011Speed: 270.55 samples/sec#011loss=7.517154\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 250, \"sum\": 250.0, \"min\": 250}, \"update.time\": {\"count\": 1, \"max\": 1292.726993560791, \"sum\": 1292.726993560791, \"min\": 1292.726993560791}}, \"EndTime\": 1517703635.281245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703633.971235}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ebb1fb60-82c3-441f-99d8-9331d5793e68-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.483928680419922, \"sum\": 14.483928680419922, \"min\": 14.483928680419922}}, \"EndTime\": 1517703635.295943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703635.281314}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] Epoch[1] Batch[0] avg_epoch_loss=7.573698\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] Epoch[1] Batch[5] avg_epoch_loss=7.455543\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:35 INFO 140150847625024] Epoch[1] Batch [5]#011Speed: 287.46 samples/sec#011loss=7.455543\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:36 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1029.5701026916504, \"sum\": 1029.5701026916504, \"min\": 1029.5701026916504}}, \"EndTime\": 1517703636.340312, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703635.29599}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:36 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:36 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_bbab6273-c58e-41f9-b086-2f1c39ac4328-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.297796249389648, \"sum\": 13.297796249389648, \"min\": 13.297796249389648}}, \"EndTime\": 1517703636.353883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703636.340429}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:36 INFO 140150847625024] Epoch[2] Batch[0] avg_epoch_loss=7.413939\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:36 INFO 140150847625024] Epoch[2] Batch[5] avg_epoch_loss=7.345106\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:36 INFO 140150847625024] Epoch[2] Batch [5]#011Speed: 281.28 samples/sec#011loss=7.345106\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:37 INFO 140150847625024] Epoch[2] Batch[10] avg_epoch_loss=7.282527\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:37 INFO 140150847625024] Epoch[2] Batch [10]#011Speed: 347.15 samples/sec#011loss=7.207432\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:37 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1083.6451053619385, \"sum\": 1083.6451053619385, \"min\": 1083.6451053619385}}, \"EndTime\": 1517703637.452772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703636.353923}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:37 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:37 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_658acab6-f2ca-4896-96d2-07b7daa7832e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.860944747924805, \"sum\": 59.860944747924805, \"min\": 59.860944747924805}}, \"EndTime\": 1517703637.512936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703637.452863}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:37 INFO 140150847625024] Epoch[3] Batch[0] avg_epoch_loss=7.272636\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] Epoch[3] Batch[5] avg_epoch_loss=30.830902\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] Epoch[3] Batch [5]#011Speed: 335.36 samples/sec#011loss=30.830902\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] Epoch[3] Batch[10] avg_epoch_loss=32.519095\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] Epoch[3] Batch [10]#011Speed: 301.11 samples/sec#011loss=34.544927\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1131.500005722046, \"sum\": 1131.500005722046, \"min\": 1131.500005722046}}, \"EndTime\": 1517703638.660373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703637.51299}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:38 INFO 140150847625024] Epoch[4] Batch[0] avg_epoch_loss=7.155682\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] Epoch[4] Batch[5] avg_epoch_loss=7.090045\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] Epoch[4] Batch [5]#011Speed: 273.23 samples/sec#011loss=7.090045\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] Epoch[4] Batch[10] avg_epoch_loss=7.064467\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] Epoch[4] Batch [10]#011Speed: 374.84 samples/sec#011loss=7.033775\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1054.0051460266113, \"sum\": 1054.0051460266113, \"min\": 1054.0051460266113}}, \"EndTime\": 1517703639.730462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703638.660435}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5a09f586-fb81-469f-b30e-87aba7d11361-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.71393394470215, \"sum\": 61.71393394470215, \"min\": 61.71393394470215}}, \"EndTime\": 1517703639.792405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703639.730522}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:39 INFO 140150847625024] Epoch[5] Batch[0] avg_epoch_loss=7.117189\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:40 INFO 140150847625024] Epoch[5] Batch[5] avg_epoch_loss=7.011993\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:40 INFO 140150847625024] Epoch[5] Batch [5]#011Speed: 382.19 samples/sec#011loss=7.011993\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:40 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 876.2378692626953, \"sum\": 876.2378692626953, \"min\": 876.2378692626953}}, \"EndTime\": 1517703640.68259, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703639.792502}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:40 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:40 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_1945e339-1ed9-4b79-898e-5d8fb0f2a920-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 55.52196502685547, \"sum\": 55.52196502685547, \"min\": 55.52196502685547}}, \"EndTime\": 1517703640.738331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703640.682649}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:40 INFO 140150847625024] Epoch[6] Batch[0] avg_epoch_loss=6.982481\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:41 INFO 140150847625024] Epoch[6] Batch[5] avg_epoch_loss=6.905635\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:41 INFO 140150847625024] Epoch[6] Batch [5]#011Speed: 326.89 samples/sec#011loss=6.905635\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:41 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1012.7928256988525, \"sum\": 1012.7928256988525, \"min\": 1012.7928256988525}}, \"EndTime\": 1517703641.766062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703640.738389}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:41 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:41 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_eb47f875-d024-45ea-ba15-244419d9bd4e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 53.327083587646484, \"sum\": 53.327083587646484, \"min\": 53.327083587646484}}, \"EndTime\": 1517703641.819634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703641.766134}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:41 INFO 140150847625024] Epoch[7] Batch[0] avg_epoch_loss=7.002211\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:42 INFO 140150847625024] Epoch[7] Batch[5] avg_epoch_loss=18.085872\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:42 INFO 140150847625024] Epoch[7] Batch [5]#011Speed: 341.08 samples/sec#011loss=18.085872\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:42 INFO 140150847625024] Epoch[7] Batch[10] avg_epoch_loss=12.971779\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:42 INFO 140150847625024] Epoch[7] Batch [10]#011Speed: 304.26 samples/sec#011loss=6.834867\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:42 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1109.4191074371338, \"sum\": 1109.4191074371338, \"min\": 1109.4191074371338}}, \"EndTime\": 1517703642.943321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703641.819692}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:42 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] Epoch[8] Batch[0] avg_epoch_loss=6.846478\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] Epoch[8] Batch[5] avg_epoch_loss=6.827854\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] Epoch[8] Batch [5]#011Speed: 288.29 samples/sec#011loss=6.827854\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] Epoch[8] Batch[10] avg_epoch_loss=6.779662\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] Epoch[8] Batch [10]#011Speed: 364.61 samples/sec#011loss=6.721831\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1041.0969257354736, \"sum\": 1041.0969257354736, \"min\": 1041.0969257354736}}, \"EndTime\": 1517703643.999585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703642.943396}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:43 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:44 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8ea455fb-ab3e-4f8e-b23c-9a61e98e5771-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.65601921081543, \"sum\": 64.65601921081543, \"min\": 64.65601921081543}}, \"EndTime\": 1517703644.064498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703643.999651}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:44 INFO 140150847625024] Epoch[9] Batch[0] avg_epoch_loss=6.761557\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:44 INFO 140150847625024] Epoch[9] Batch[5] avg_epoch_loss=6.734129\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:44 INFO 140150847625024] Epoch[9] Batch [5]#011Speed: 346.45 samples/sec#011loss=6.734129\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] Epoch[9] Batch[10] avg_epoch_loss=6.679390\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] Epoch[9] Batch [10]#011Speed: 277.72 samples/sec#011loss=6.613703\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1158.9159965515137, \"sum\": 1158.9159965515137, \"min\": 1158.9159965515137}}, \"EndTime\": 1517703645.235614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703644.064557}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_e90b9257-1303-4174-9448-11de0c14eebd-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.91513442993164, \"sum\": 12.91513442993164, \"min\": 12.91513442993164}}, \"EndTime\": 1517703645.248738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703645.235678}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] Epoch[10] Batch[0] avg_epoch_loss=6.782389\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] Epoch[10] Batch[5] avg_epoch_loss=6.662640\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:45 INFO 140150847625024] Epoch[10] Batch [5]#011Speed: 280.28 samples/sec#011loss=6.662640\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:46 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1008.5620880126953, \"sum\": 1008.5620880126953, \"min\": 1008.5620880126953}}, \"EndTime\": 1517703646.26942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703645.248784}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:46 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:46 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5c9a2768-afed-44b8-afc6-6f1ba911a5b4-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.748003005981445, \"sum\": 12.748003005981445, \"min\": 12.748003005981445}}, \"EndTime\": 1517703646.282354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703646.26947}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:46 INFO 140150847625024] Epoch[11] Batch[0] avg_epoch_loss=6.669790\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:46 INFO 140150847625024] Epoch[11] Batch[5] avg_epoch_loss=6.665254\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:46 INFO 140150847625024] Epoch[11] Batch [5]#011Speed: 294.09 samples/sec#011loss=6.665254\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] Epoch[11] Batch[10] avg_epoch_loss=6.622961\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] Epoch[11] Batch [10]#011Speed: 368.42 samples/sec#011loss=6.572209\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1018.190860748291, \"sum\": 1018.190860748291, \"min\": 1018.190860748291}}, \"EndTime\": 1517703647.313137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703646.282391}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_d4f9da80-1dfc-4752-b23a-626e727f59ec-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 66.23601913452148, \"sum\": 66.23601913452148, \"min\": 66.23601913452148}}, \"EndTime\": 1517703647.379621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703647.3132}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] Epoch[12] Batch[0] avg_epoch_loss=6.632514\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] Epoch[12] Batch[5] avg_epoch_loss=6.560223\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:47 INFO 140150847625024] Epoch[12] Batch [5]#011Speed: 345.87 samples/sec#011loss=6.560223\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:48 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 986.3040447235107, \"sum\": 986.3040447235107, \"min\": 986.3040447235107}}, \"EndTime\": 1517703648.378487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703647.379669}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:48 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:48 INFO 140150847625024] Epoch[13] Batch[0] avg_epoch_loss=6.471566\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:20:48 INFO 140150847625024] Epoch[13] Batch[5] avg_epoch_loss=6.501285\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:48 INFO 140150847625024] Epoch[13] Batch [5]#011Speed: 352.89 samples/sec#011loss=6.501285\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:49 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 996.9680309295654, \"sum\": 996.9680309295654, \"min\": 996.9680309295654}}, \"EndTime\": 1517703649.388432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703648.378538}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:49 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:49 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8c6612fb-fc74-4385-8ebf-4a1321a7b1d4-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 55.47690391540527, \"sum\": 55.47690391540527, \"min\": 55.47690391540527}}, \"EndTime\": 1517703649.444176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703649.388515}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:49 INFO 140150847625024] Epoch[14] Batch[0] avg_epoch_loss=6.438689\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] Epoch[14] Batch[5] avg_epoch_loss=6.470707\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] Epoch[14] Batch [5]#011Speed: 357.62 samples/sec#011loss=6.470707\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] Epoch[14] Batch[10] avg_epoch_loss=6.465285\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] Epoch[14] Batch [10]#011Speed: 283.67 samples/sec#011loss=6.458778\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1109.1911792755127, \"sum\": 1109.1911792755127, \"min\": 1109.1911792755127}}, \"EndTime\": 1517703650.565443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703649.44423}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_e5b18797-fc26-438d-8c41-78a5361600e8-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.076066970825195, \"sum\": 13.076066970825195, \"min\": 13.076066970825195}}, \"EndTime\": 1517703650.578731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703650.565507}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:50 INFO 140150847625024] Epoch[15] Batch[0] avg_epoch_loss=6.478752\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:51 INFO 140150847625024] Epoch[15] Batch[5] avg_epoch_loss=6.410015\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:51 INFO 140150847625024] Epoch[15] Batch [5]#011Speed: 276.49 samples/sec#011loss=6.410015\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:51 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1012.5019550323486, \"sum\": 1012.5019550323486, \"min\": 1012.5019550323486}}, \"EndTime\": 1517703651.603263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703650.578777}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:51 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:51 INFO 140150847625024] Epoch[16] Batch[0] avg_epoch_loss=6.414747\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] Epoch[16] Batch[5] avg_epoch_loss=6.438135\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] Epoch[16] Batch [5]#011Speed: 269.18 samples/sec#011loss=6.438135\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] Epoch[16] Batch[10] avg_epoch_loss=6.390617\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] Epoch[16] Batch [10]#011Speed: 345.60 samples/sec#011loss=6.333596\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1103.187084197998, \"sum\": 1103.187084197998, \"min\": 1103.187084197998}}, \"EndTime\": 1517703652.720936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703651.603341}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_22931040-546c-4537-8d78-541a04b519b3-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.90890884399414, \"sum\": 65.90890884399414, \"min\": 65.90890884399414}}, \"EndTime\": 1517703652.787053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703652.72099}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:52 INFO 140150847625024] Epoch[17] Batch[0] avg_epoch_loss=6.298292\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:53 INFO 140150847625024] Epoch[17] Batch[5] avg_epoch_loss=6.341525\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:53 INFO 140150847625024] Epoch[17] Batch [5]#011Speed: 338.80 samples/sec#011loss=6.341525\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:53 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 987.982988357544, \"sum\": 987.982988357544, \"min\": 987.982988357544}}, \"EndTime\": 1517703653.78748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703652.787098}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:53 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:53 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_378879d4-323a-41a9-8a55-7e4cf6436a79-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 52.79994010925293, \"sum\": 52.79994010925293, \"min\": 52.79994010925293}}, \"EndTime\": 1517703653.840466, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703653.787535}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:53 INFO 140150847625024] Epoch[18] Batch[0] avg_epoch_loss=6.393117\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] Epoch[18] Batch[5] avg_epoch_loss=6.320231\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] Epoch[18] Batch [5]#011Speed: 357.73 samples/sec#011loss=6.320231\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] Epoch[18] Batch[10] avg_epoch_loss=6.325609\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] Epoch[18] Batch [10]#011Speed: 304.78 samples/sec#011loss=6.332062\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1075.0341415405273, \"sum\": 1075.0341415405273, \"min\": 1075.0341415405273}}, \"EndTime\": 1517703654.927855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703653.84051}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:54 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_25fbae9d-d536-458e-93ac-0520adf5c80c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.241052627563477, \"sum\": 13.241052627563477, \"min\": 13.241052627563477}}, \"EndTime\": 1517703654.941307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703654.927917}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:55 INFO 140150847625024] Epoch[19] Batch[0] avg_epoch_loss=6.391616\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:55 INFO 140150847625024] Epoch[19] Batch[5] avg_epoch_loss=6.320768\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:55 INFO 140150847625024] Epoch[19] Batch [5]#011Speed: 283.22 samples/sec#011loss=6.320768\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:55 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1012.8471851348877, \"sum\": 1012.8471851348877, \"min\": 1012.8471851348877}}, \"EndTime\": 1517703655.966432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703654.941356}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:55 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:55 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_c0742035-5a6e-4723-833f-4bae35035616-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.190984725952148, \"sum\": 13.190984725952148, \"min\": 13.190984725952148}}, \"EndTime\": 1517703655.979828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703655.966492}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:56 INFO 140150847625024] Epoch[20] Batch[0] avg_epoch_loss=6.257042\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:56 INFO 140150847625024] Epoch[20] Batch[5] avg_epoch_loss=28.713103\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:56 INFO 140150847625024] Epoch[20] Batch [5]#011Speed: 278.17 samples/sec#011loss=28.713103\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:57 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1040.626049041748, \"sum\": 1040.626049041748, \"min\": 1040.626049041748}}, \"EndTime\": 1517703657.031977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703655.979873}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:57 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:57 INFO 140150847625024] Epoch[21] Batch[0] avg_epoch_loss=6.358994\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:57 INFO 140150847625024] Epoch[21] Batch[5] avg_epoch_loss=6.238666\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:57 INFO 140150847625024] Epoch[21] Batch [5]#011Speed: 275.65 samples/sec#011loss=6.238666\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:58 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1015.4969692230225, \"sum\": 1015.4969692230225, \"min\": 1015.4969692230225}}, \"EndTime\": 1517703658.060059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703657.032035}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:58 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:58 INFO 140150847625024] Epoch[22] Batch[0] avg_epoch_loss=6.319744\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:58 INFO 140150847625024] Epoch[22] Batch[5] avg_epoch_loss=6.237652\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:58 INFO 140150847625024] Epoch[22] Batch [5]#011Speed: 292.56 samples/sec#011loss=6.237652\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] Epoch[22] Batch[10] avg_epoch_loss=6.207907\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] Epoch[22] Batch [10]#011Speed: 343.60 samples/sec#011loss=6.172213\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1053.8179874420166, \"sum\": 1053.8179874420166, \"min\": 1053.8179874420166}}, \"EndTime\": 1517703659.125933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703658.060121}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_7ba08f57-b25e-4ad6-a5f8-81cdd2d544e3-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.53790855407715, \"sum\": 62.53790855407715, \"min\": 62.53790855407715}}, \"EndTime\": 1517703659.188657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703659.125983}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] Epoch[23] Batch[0] avg_epoch_loss=6.231892\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] Epoch[23] Batch[5] avg_epoch_loss=6.167548\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:20:59 INFO 140150847625024] Epoch[23] Batch [5]#011Speed: 335.18 samples/sec#011loss=6.167548\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:00 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 978.4889221191406, \"sum\": 978.4889221191406, \"min\": 978.4889221191406}}, \"EndTime\": 1517703660.180112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703659.18872}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:00 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:00 INFO 140150847625024] Epoch[24] Batch[0] avg_epoch_loss=6.195416\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:00 INFO 140150847625024] Epoch[24] Batch[5] avg_epoch_loss=6.142234\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:00 INFO 140150847625024] Epoch[24] Batch [5]#011Speed: 359.04 samples/sec#011loss=6.142234\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:01 INFO 140150847625024] Epoch[24] Batch[10] avg_epoch_loss=6.144908\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:01 INFO 140150847625024] Epoch[24] Batch [10]#011Speed: 282.49 samples/sec#011loss=6.148117\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:01 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1180.9980869293213, \"sum\": 1180.9980869293213, \"min\": 1180.9980869293213}}, \"EndTime\": 1517703661.373828, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703660.180192}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:01 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:01 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_a0eab02f-f476-48e5-8f6a-c144805d78fd-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.015985488891602, \"sum\": 13.015985488891602, \"min\": 13.015985488891602}}, \"EndTime\": 1517703661.387044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703661.37389}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:01 INFO 140150847625024] Epoch[25] Batch[0] avg_epoch_loss=6.184213\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:02 INFO 140150847625024] Epoch[25] Batch[5] avg_epoch_loss=6.129837\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:02 INFO 140150847625024] Epoch[25] Batch [5]#011Speed: 280.41 samples/sec#011loss=6.129837\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:02 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1042.738914489746, \"sum\": 1042.738914489746, \"min\": 1042.738914489746}}, \"EndTime\": 1517703662.448224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703661.387094}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:02 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:02 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5c26b559-a8d5-4174-89bd-ecbdea817286-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.383150100708008, \"sum\": 13.383150100708008, \"min\": 13.383150100708008}}, \"EndTime\": 1517703662.461914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703662.448298}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:02 INFO 140150847625024] Epoch[26] Batch[0] avg_epoch_loss=6.176690\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] Epoch[26] Batch[5] avg_epoch_loss=27.742517\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] Epoch[26] Batch [5]#011Speed: 268.92 samples/sec#011loss=27.742517\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] Epoch[26] Batch[10] avg_epoch_loss=23.629087\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] Epoch[26] Batch [10]#011Speed: 338.77 samples/sec#011loss=18.692972\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1262.3310089111328, \"sum\": 1262.3310089111328, \"min\": 1262.3310089111328}}, \"EndTime\": 1517703663.741457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703662.46196}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:03 INFO 140150847625024] Epoch[27] Batch[0] avg_epoch_loss=136.239822\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:04 INFO 140150847625024] Epoch[27] Batch[5] avg_epoch_loss=27.773004\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:04 INFO 140150847625024] Epoch[27] Batch [5]#011Speed: 282.43 samples/sec#011loss=27.773004\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:04 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1034.796953201294, \"sum\": 1034.796953201294, \"min\": 1034.796953201294}}, \"EndTime\": 1517703664.791804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703663.741535}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:04 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:04 INFO 140150847625024] Epoch[28] Batch[0] avg_epoch_loss=6.131108\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:05 INFO 140150847625024] Epoch[28] Batch[5] avg_epoch_loss=6.101468\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:05 INFO 140150847625024] Epoch[28] Batch [5]#011Speed: 279.08 samples/sec#011loss=6.101468\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:05 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1039.0679836273193, \"sum\": 1039.0679836273193, \"min\": 1039.0679836273193}}, \"EndTime\": 1517703665.846327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703664.791867}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:05 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:05 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8de99f6c-09bd-42bb-8d69-fb680bb465a6-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.60011100769043, \"sum\": 13.60011100769043, \"min\": 13.60011100769043}}, \"EndTime\": 1517703665.860171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703665.846403}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:05 INFO 140150847625024] Epoch[29] Batch[0] avg_epoch_loss=6.156974\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:06 INFO 140150847625024] Epoch[29] Batch[5] avg_epoch_loss=6.073742\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:06 INFO 140150847625024] Epoch[29] Batch [5]#011Speed: 284.63 samples/sec#011loss=6.073742\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:06 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1007.7579021453857, \"sum\": 1007.7579021453857, \"min\": 1007.7579021453857}}, \"EndTime\": 1517703666.882547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703665.860216}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:06 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:06 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_860aa8f9-4043-4665-82b2-1e10429376af-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.67497444152832, \"sum\": 13.67497444152832, \"min\": 13.67497444152832}}, \"EndTime\": 1517703666.896469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703666.882623}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:06 INFO 140150847625024] Epoch[30] Batch[0] avg_epoch_loss=5.984807\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:07 INFO 140150847625024] Epoch[30] Batch[5] avg_epoch_loss=6.014358\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:07 INFO 140150847625024] Epoch[30] Batch [5]#011Speed: 275.18 samples/sec#011loss=6.014358\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:07 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1018.7602043151855, \"sum\": 1018.7602043151855, \"min\": 1018.7602043151855}}, \"EndTime\": 1517703667.930614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703666.89652}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:07 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:07 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_485ae27f-e42e-4c05-9a4c-42ce2cfd96c7-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.68403434753418, \"sum\": 13.68403434753418, \"min\": 13.68403434753418}}, \"EndTime\": 1517703667.944493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703667.930673}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:07 INFO 140150847625024] Epoch[31] Batch[0] avg_epoch_loss=6.091338\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:08 INFO 140150847625024] Epoch[31] Batch[5] avg_epoch_loss=16.215156\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:08 INFO 140150847625024] Epoch[31] Batch [5]#011Speed: 284.95 samples/sec#011loss=16.215156\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:08 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 991.3511276245117, \"sum\": 991.3511276245117, \"min\": 991.3511276245117}}, \"EndTime\": 1517703668.950973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703667.944531}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:08 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:21:09 INFO 140150847625024] Epoch[32] Batch[0] avg_epoch_loss=5.987778\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:09 INFO 140150847625024] Epoch[32] Batch[5] avg_epoch_loss=5.958595\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:09 INFO 140150847625024] Epoch[32] Batch [5]#011Speed: 265.36 samples/sec#011loss=5.958595\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:10 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1113.508939743042, \"sum\": 1113.508939743042, \"min\": 1113.508939743042}}, \"EndTime\": 1517703670.076674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703668.951034}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:10 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:10 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_989019e9-ba9e-4a29-bd27-1591110b22e9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.633012771606445, \"sum\": 13.633012771606445, \"min\": 13.633012771606445}}, \"EndTime\": 1517703670.090526, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703670.07674}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:10 INFO 140150847625024] Epoch[33] Batch[0] avg_epoch_loss=6.076145\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:10 INFO 140150847625024] Epoch[33] Batch[5] avg_epoch_loss=5.989979\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:10 INFO 140150847625024] Epoch[33] Batch [5]#011Speed: 263.60 samples/sec#011loss=5.989979\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:11 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1069.3559646606445, \"sum\": 1069.3559646606445, \"min\": 1069.3559646606445}}, \"EndTime\": 1517703671.172566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703670.0906}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:11 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:11 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_045b11b9-83c4-4258-990e-d0854b9b7cb4-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.170957565307617, \"sum\": 13.170957565307617, \"min\": 13.170957565307617}}, \"EndTime\": 1517703671.185959, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703671.172632}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:11 INFO 140150847625024] Epoch[34] Batch[0] avg_epoch_loss=5.996686\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:11 INFO 140150847625024] Epoch[34] Batch[5] avg_epoch_loss=5.964384\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:11 INFO 140150847625024] Epoch[34] Batch [5]#011Speed: 279.69 samples/sec#011loss=5.964384\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:12 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1062.6051425933838, \"sum\": 1062.6051425933838, \"min\": 1062.6051425933838}}, \"EndTime\": 1517703672.26143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703671.186006}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:12 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:12 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_c71b56a4-2a93-4a82-9482-6608481bad8c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.221097946166992, \"sum\": 12.221097946166992, \"min\": 12.221097946166992}}, \"EndTime\": 1517703672.273824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703672.26148}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:12 INFO 140150847625024] Epoch[35] Batch[0] avg_epoch_loss=5.979020\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:12 INFO 140150847625024] Epoch[35] Batch[5] avg_epoch_loss=5.972814\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:12 INFO 140150847625024] Epoch[35] Batch [5]#011Speed: 284.69 samples/sec#011loss=5.972814\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:13 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1031.5730571746826, \"sum\": 1031.5730571746826, \"min\": 1031.5730571746826}}, \"EndTime\": 1517703673.317196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703672.273867}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:13 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:13 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ae2e9770-be85-4492-95c2-81b100e2fb3d-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.993978500366211, \"sum\": 13.993978500366211, \"min\": 13.993978500366211}}, \"EndTime\": 1517703673.331377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703673.317248}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:13 INFO 140150847625024] Epoch[36] Batch[0] avg_epoch_loss=5.946028\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:13 INFO 140150847625024] Epoch[36] Batch[5] avg_epoch_loss=5.921981\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:13 INFO 140150847625024] Epoch[36] Batch [5]#011Speed: 286.47 samples/sec#011loss=5.921981\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:14 INFO 140150847625024] Epoch[36] Batch[10] avg_epoch_loss=5.939828\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:14 INFO 140150847625024] Epoch[36] Batch [10]#011Speed: 334.43 samples/sec#011loss=5.961246\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:14 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1071.2621212005615, \"sum\": 1071.2621212005615, \"min\": 1071.2621212005615}}, \"EndTime\": 1517703674.414924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703673.331422}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:14 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:14 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_dcb2698c-513a-43f5-8756-5844f4f5c8bf-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 52.81400680541992, \"sum\": 52.81400680541992, \"min\": 52.81400680541992}}, \"EndTime\": 1517703674.467943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703674.414975}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:14 INFO 140150847625024] Epoch[37] Batch[0] avg_epoch_loss=5.943288\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] Epoch[37] Batch[5] avg_epoch_loss=15.993789\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] Epoch[37] Batch [5]#011Speed: 337.58 samples/sec#011loss=15.993789\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] Epoch[37] Batch[10] avg_epoch_loss=11.416691\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] Epoch[37] Batch [10]#011Speed: 260.26 samples/sec#011loss=5.924172\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1215.3100967407227, \"sum\": 1215.3100967407227, \"min\": 1215.3100967407227}}, \"EndTime\": 1517703675.695728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703674.467989}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:15 INFO 140150847625024] Epoch[38] Batch[0] avg_epoch_loss=5.914320\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] Epoch[38] Batch[5] avg_epoch_loss=5.905204\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] Epoch[38] Batch [5]#011Speed: 274.70 samples/sec#011loss=5.905204\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] Epoch[38] Batch[10] avg_epoch_loss=5.923787\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] Epoch[38] Batch [10]#011Speed: 368.76 samples/sec#011loss=5.946086\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1066.107988357544, \"sum\": 1066.107988357544, \"min\": 1066.107988357544}}, \"EndTime\": 1517703676.774054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703675.695799}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_bdc4c51b-1d2f-4743-9881-f0870e84dbcf-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 54.785966873168945, \"sum\": 54.785966873168945, \"min\": 54.785966873168945}}, \"EndTime\": 1517703676.829039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703676.774107}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:16 INFO 140150847625024] Epoch[39] Batch[0] avg_epoch_loss=5.915925\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:17 INFO 140150847625024] Epoch[39] Batch[5] avg_epoch_loss=5.873041\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:17 INFO 140150847625024] Epoch[39] Batch [5]#011Speed: 336.22 samples/sec#011loss=5.873041\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:17 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 974.2581844329834, \"sum\": 974.2581844329834, \"min\": 974.2581844329834}}, \"EndTime\": 1517703677.815964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703676.829089}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:17 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:17 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8727d9d7-76dc-48c9-947a-adc030909784-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 53.88998985290527, \"sum\": 53.88998985290527, \"min\": 53.88998985290527}}, \"EndTime\": 1517703677.870037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703677.816016}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:17 INFO 140150847625024] Epoch[40] Batch[0] avg_epoch_loss=5.912915\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:18 INFO 140150847625024] Epoch[40] Batch[5] avg_epoch_loss=26.561423\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:18 INFO 140150847625024] Epoch[40] Batch [5]#011Speed: 348.46 samples/sec#011loss=26.561423\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:21:18 INFO 140150847625024] Epoch[40] Batch[10] avg_epoch_loss=22.532650\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:18 INFO 140150847625024] Epoch[40] Batch [10]#011Speed: 290.61 samples/sec#011loss=17.698123\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:18 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1109.6000671386719, \"sum\": 1109.6000671386719, \"min\": 1109.6000671386719}}, \"EndTime\": 1517703678.991831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703677.870079}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:18 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:19 INFO 140150847625024] Epoch[41] Batch[0] avg_epoch_loss=5.831269\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:19 INFO 140150847625024] Epoch[41] Batch[5] avg_epoch_loss=5.887446\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:19 INFO 140150847625024] Epoch[41] Batch [5]#011Speed: 288.13 samples/sec#011loss=5.887446\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:19 INFO 140150847625024] processed a total of 288 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 839.3011093139648, \"sum\": 839.3011093139648, \"min\": 839.3011093139648}}, \"EndTime\": 1517703679.843149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703678.99188}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:19 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:20 INFO 140150847625024] Epoch[42] Batch[0] avg_epoch_loss=5.830354\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:20 INFO 140150847625024] Epoch[42] Batch[5] avg_epoch_loss=5.855394\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:20 INFO 140150847625024] Epoch[42] Batch [5]#011Speed: 329.49 samples/sec#011loss=5.855394\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] Epoch[42] Batch[10] avg_epoch_loss=11.217888\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] Epoch[42] Batch [10]#011Speed: 291.38 samples/sec#011loss=17.652881\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1183.6938858032227, \"sum\": 1183.6938858032227, \"min\": 1183.6938858032227}}, \"EndTime\": 1517703681.038803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703679.843208}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] Epoch[43] Batch[0] avg_epoch_loss=129.322159\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] Epoch[43] Batch[5] avg_epoch_loss=26.427873\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:21 INFO 140150847625024] Epoch[43] Batch [5]#011Speed: 278.31 samples/sec#011loss=26.427873\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:22 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1003.9820671081543, \"sum\": 1003.9820671081543, \"min\": 1003.9820671081543}}, \"EndTime\": 1517703682.05486, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703681.038853}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:22 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:22 INFO 140150847625024] Epoch[44] Batch[0] avg_epoch_loss=5.887735\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:22 INFO 140150847625024] Epoch[44] Batch[5] avg_epoch_loss=5.855929\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:22 INFO 140150847625024] Epoch[44] Batch [5]#011Speed: 268.97 samples/sec#011loss=5.855929\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] Epoch[44] Batch[10] avg_epoch_loss=5.845129\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] Epoch[44] Batch [10]#011Speed: 328.63 samples/sec#011loss=5.832169\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1133.908987045288, \"sum\": 1133.908987045288, \"min\": 1133.908987045288}}, \"EndTime\": 1517703683.201136, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703682.054911}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_7b0f8bbf-cc3a-4219-b47c-23a47cb24e68-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.990116119384766, \"sum\": 63.990116119384766, \"min\": 63.990116119384766}}, \"EndTime\": 1517703683.265332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703683.201202}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] Epoch[45] Batch[0] avg_epoch_loss=5.805848\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] Epoch[45] Batch[5] avg_epoch_loss=5.866655\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:23 INFO 140150847625024] Epoch[45] Batch [5]#011Speed: 314.50 samples/sec#011loss=5.866655\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:24 INFO 140150847625024] Epoch[45] Batch[10] avg_epoch_loss=27.692232\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:24 INFO 140150847625024] Epoch[45] Batch [10]#011Speed: 283.20 samples/sec#011loss=53.882924\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:24 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1186.9118213653564, \"sum\": 1186.9118213653564, \"min\": 1186.9118213653564}}, \"EndTime\": 1517703684.464583, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703683.265391}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:24 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:24 INFO 140150847625024] Epoch[46] Batch[0] avg_epoch_loss=5.825341\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:25 INFO 140150847625024] Epoch[46] Batch[5] avg_epoch_loss=25.828132\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:25 INFO 140150847625024] Epoch[46] Batch [5]#011Speed: 295.90 samples/sec#011loss=25.828132\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:25 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1041.0330295562744, \"sum\": 1041.0330295562744, \"min\": 1041.0330295562744}}, \"EndTime\": 1517703685.517903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703684.464634}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:25 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:25 INFO 140150847625024] Epoch[47] Batch[0] avg_epoch_loss=5.886825\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] Epoch[47] Batch[5] avg_epoch_loss=25.496378\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] Epoch[47] Batch [5]#011Speed: 283.37 samples/sec#011loss=25.496378\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] Epoch[47] Batch[10] avg_epoch_loss=16.531681\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] Epoch[47] Batch [10]#011Speed: 338.19 samples/sec#011loss=5.774044\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1074.8529434204102, \"sum\": 1074.8529434204102, \"min\": 1074.8529434204102}}, \"EndTime\": 1517703686.604785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703685.517956}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:26 INFO 140150847625024] Epoch[48] Batch[0] avg_epoch_loss=5.823996\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:27 INFO 140150847625024] Epoch[48] Batch[5] avg_epoch_loss=5.844227\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:27 INFO 140150847625024] Epoch[48] Batch [5]#011Speed: 323.40 samples/sec#011loss=5.844227\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:27 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1029.1049480438232, \"sum\": 1029.1049480438232, \"min\": 1029.1049480438232}}, \"EndTime\": 1517703687.650684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703686.604853}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:27 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:27 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_787c96a5-2ffc-4912-9b8e-c0893d44f67b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 55.29499053955078, \"sum\": 55.29499053955078, \"min\": 55.29499053955078}}, \"EndTime\": 1517703687.706249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703687.650763}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:27 INFO 140150847625024] Epoch[49] Batch[0] avg_epoch_loss=5.768554\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] Epoch[49] Batch[5] avg_epoch_loss=5.761363\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] Epoch[49] Batch [5]#011Speed: 345.84 samples/sec#011loss=5.761363\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] Epoch[49] Batch[10] avg_epoch_loss=5.760155\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] Epoch[49] Batch [10]#011Speed: 274.13 samples/sec#011loss=5.758706\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1155.4980278015137, \"sum\": 1155.4980278015137, \"min\": 1155.4980278015137}}, \"EndTime\": 1517703688.877047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703687.706314}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_e444e29a-7659-4c38-9bc2-efcf5eef89c4-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.585805892944336, \"sum\": 13.585805892944336, \"min\": 13.585805892944336}}, \"EndTime\": 1517703688.890826, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703688.877096}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:28 INFO 140150847625024] Epoch[50] Batch[0] avg_epoch_loss=5.783965\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:21:29 INFO 140150847625024] Epoch[50] Batch[5] avg_epoch_loss=5.782816\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:29 INFO 140150847625024] Epoch[50] Batch [5]#011Speed: 276.22 samples/sec#011loss=5.782816\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:29 INFO 140150847625024] Epoch[50] Batch[10] avg_epoch_loss=5.768560\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:29 INFO 140150847625024] Epoch[50] Batch [10]#011Speed: 341.05 samples/sec#011loss=5.751453\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:30 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1240.0500774383545, \"sum\": 1240.0500774383545, \"min\": 1240.0500774383545}}, \"EndTime\": 1517703690.143049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703688.890868}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:30 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:30 INFO 140150847625024] Epoch[51] Batch[0] avg_epoch_loss=121.692101\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:30 INFO 140150847625024] Epoch[51] Batch[5] avg_epoch_loss=25.093840\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:30 INFO 140150847625024] Epoch[51] Batch [5]#011Speed: 274.60 samples/sec#011loss=25.093840\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] Epoch[51] Batch[10] avg_epoch_loss=16.295621\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] Epoch[51] Batch [10]#011Speed: 365.02 samples/sec#011loss=5.737758\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1081.812858581543, \"sum\": 1081.812858581543, \"min\": 1081.812858581543}}, \"EndTime\": 1517703691.236904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703690.143099}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] Epoch[52] Batch[0] avg_epoch_loss=5.817292\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] Epoch[52] Batch[5] avg_epoch_loss=5.756932\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:31 INFO 140150847625024] Epoch[52] Batch [5]#011Speed: 338.65 samples/sec#011loss=5.756932\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:32 INFO 140150847625024] Epoch[52] Batch[10] avg_epoch_loss=5.758409\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:32 INFO 140150847625024] Epoch[52] Batch [10]#011Speed: 269.60 samples/sec#011loss=5.760181\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:32 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1233.6819171905518, \"sum\": 1233.6819171905518, \"min\": 1233.6819171905518}}, \"EndTime\": 1517703692.483713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703691.236963}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:32 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:32 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_70acf720-63e9-400e-b818-c9e53afa6d90-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.278007507324219, \"sum\": 13.278007507324219, \"min\": 13.278007507324219}}, \"EndTime\": 1517703692.497201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703692.483776}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:32 INFO 140150847625024] Epoch[53] Batch[0] avg_epoch_loss=5.786549\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] Epoch[53] Batch[5] avg_epoch_loss=5.785159\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] Epoch[53] Batch [5]#011Speed: 291.04 samples/sec#011loss=5.785159\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] Epoch[53] Batch[10] avg_epoch_loss=5.774073\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] Epoch[53] Batch [10]#011Speed: 340.25 samples/sec#011loss=5.760770\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1075.523853302002, \"sum\": 1075.523853302002, \"min\": 1075.523853302002}}, \"EndTime\": 1517703693.584557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703692.497246}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:33 INFO 140150847625024] Epoch[54] Batch[0] avg_epoch_loss=5.698634\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:34 INFO 140150847625024] Epoch[54] Batch[5] avg_epoch_loss=5.765421\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:34 INFO 140150847625024] Epoch[54] Batch [5]#011Speed: 341.74 samples/sec#011loss=5.765421\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:34 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 958.5480690002441, \"sum\": 958.5480690002441, \"min\": 958.5480690002441}}, \"EndTime\": 1517703694.560003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703693.584621}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:34 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:34 INFO 140150847625024] Epoch[55] Batch[0] avg_epoch_loss=5.788359\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] Epoch[55] Batch[5] avg_epoch_loss=5.755501\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] Epoch[55] Batch [5]#011Speed: 349.37 samples/sec#011loss=5.755501\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] Epoch[55] Batch[10] avg_epoch_loss=5.751728\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] Epoch[55] Batch [10]#011Speed: 256.95 samples/sec#011loss=5.747199\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1196.3551044464111, \"sum\": 1196.3551044464111, \"min\": 1196.3551044464111}}, \"EndTime\": 1517703695.77915, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703694.560093}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_d32b3266-73fc-4d71-acc7-8e07c652eaf0-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.273954391479492, \"sum\": 13.273954391479492, \"min\": 13.273954391479492}}, \"EndTime\": 1517703695.792634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703695.779212}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:35 INFO 140150847625024] Epoch[56] Batch[0] avg_epoch_loss=5.731155\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] Epoch[56] Batch[5] avg_epoch_loss=5.763239\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] Epoch[56] Batch [5]#011Speed: 261.01 samples/sec#011loss=5.763239\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] Epoch[56] Batch[10] avg_epoch_loss=5.745333\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] Epoch[56] Batch [10]#011Speed: 379.29 samples/sec#011loss=5.723846\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1096.0369110107422, \"sum\": 1096.0369110107422, \"min\": 1096.0369110107422}}, \"EndTime\": 1517703696.901049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703695.79268}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:36 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_7e15c7a5-1b04-446e-8fb1-78dfbd9d5a4a-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 55.02796173095703, \"sum\": 55.02796173095703, \"min\": 55.02796173095703}}, \"EndTime\": 1517703696.956303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703696.901106}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] Epoch[57] Batch[0] avg_epoch_loss=5.777745\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] Epoch[57] Batch[5] avg_epoch_loss=5.735639\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] Epoch[57] Batch [5]#011Speed: 332.99 samples/sec#011loss=5.735639\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] processed a total of 288 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 951.2021541595459, \"sum\": 951.2021541595459, \"min\": 951.2021541595459}}, \"EndTime\": 1517703697.919328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703696.956401}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_9a173f9f-7a15-44cc-8645-e86b8186ddf8-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.879060745239258, \"sum\": 13.879060745239258, \"min\": 13.879060745239258}}, \"EndTime\": 1517703697.933393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703697.919378}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:37 INFO 140150847625024] Epoch[58] Batch[0] avg_epoch_loss=5.721153\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:38 INFO 140150847625024] Epoch[58] Batch[5] avg_epoch_loss=14.978339\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:38 INFO 140150847625024] Epoch[58] Batch [5]#011Speed: 273.48 samples/sec#011loss=14.978339\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] Epoch[58] Batch[10] avg_epoch_loss=15.826391\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] Epoch[58] Batch [10]#011Speed: 342.49 samples/sec#011loss=16.844053\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1091.9899940490723, \"sum\": 1091.9899940490723, \"min\": 1091.9899940490723}}, \"EndTime\": 1517703699.037489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703697.933441}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] Epoch[59] Batch[0] avg_epoch_loss=5.731154\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] Epoch[59] Batch[5] avg_epoch_loss=5.709291\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:39 INFO 140150847625024] Epoch[59] Batch [5]#011Speed: 329.82 samples/sec#011loss=5.709291\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:40 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1023.1161117553711, \"sum\": 1023.1161117553711, \"min\": 1023.1161117553711}}, \"EndTime\": 1517703700.078446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703699.037557}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:40 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:40 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_b3f2aba7-50f3-4505-8f8f-b70505513777-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 53.05290222167969, \"sum\": 53.05290222167969, \"min\": 53.05290222167969}}, \"EndTime\": 1517703700.131722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703700.078509}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:40 INFO 140150847625024] Epoch[60] Batch[0] avg_epoch_loss=5.706492\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:40 INFO 140150847625024] Epoch[60] Batch[5] avg_epoch_loss=5.727782\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:40 INFO 140150847625024] Epoch[60] Batch [5]#011Speed: 316.89 samples/sec#011loss=5.727782\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:41 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1050.4589080810547, \"sum\": 1050.4589080810547, \"min\": 1050.4589080810547}}, \"EndTime\": 1517703701.194459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703700.13178}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:41 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:41 INFO 140150847625024] Epoch[61] Batch[0] avg_epoch_loss=5.804071\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:41 INFO 140150847625024] Epoch[61] Batch[5] avg_epoch_loss=5.712799\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:41 INFO 140150847625024] Epoch[61] Batch [5]#011Speed: 324.43 samples/sec#011loss=5.712799\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:42 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1049.9308109283447, \"sum\": 1049.9308109283447, \"min\": 1049.9308109283447}}, \"EndTime\": 1517703702.258663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703701.194536}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:42 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:42 INFO 140150847625024] Epoch[62] Batch[0] avg_epoch_loss=5.778076\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:42 INFO 140150847625024] Epoch[62] Batch[5] avg_epoch_loss=5.708848\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:42 INFO 140150847625024] Epoch[62] Batch [5]#011Speed: 319.87 samples/sec#011loss=5.708848\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:43 INFO 140150847625024] Epoch[62] Batch[10] avg_epoch_loss=5.708440\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:43 INFO 140150847625024] Epoch[62] Batch [10]#011Speed: 265.59 samples/sec#011loss=5.707950\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:43 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1246.4568614959717, \"sum\": 1246.4568614959717, \"min\": 1246.4568614959717}}, \"EndTime\": 1517703703.518607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703702.258728}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:43 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:43 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_78923034-4311-4d85-9225-bbc3ae77fb54-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.705087661743164, \"sum\": 12.705087661743164, \"min\": 12.705087661743164}}, \"EndTime\": 1517703703.531511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703703.518664}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:43 INFO 140150847625024] Epoch[63] Batch[0] avg_epoch_loss=5.760545\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:44 INFO 140150847625024] Epoch[63] Batch[5] avg_epoch_loss=5.704616\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:44 INFO 140150847625024] Epoch[63] Batch [5]#011Speed: 260.95 samples/sec#011loss=5.704616\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:44 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1077.800989151001, \"sum\": 1077.800989151001, \"min\": 1077.800989151001}}, \"EndTime\": 1517703704.623715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703703.531549}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:44 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:44 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_aeb3d212-d643-4f0a-bcc1-4397f22ecd50-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.625860214233398, \"sum\": 13.625860214233398, \"min\": 13.625860214233398}}, \"EndTime\": 1517703704.637579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703704.62379}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:44 INFO 140150847625024] Epoch[64] Batch[0] avg_epoch_loss=5.778881\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] Epoch[64] Batch[5] avg_epoch_loss=24.506654\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] Epoch[64] Batch [5]#011Speed: 271.06 samples/sec#011loss=24.506654\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] Epoch[64] Batch[10] avg_epoch_loss=15.956426\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] Epoch[64] Batch [10]#011Speed: 335.83 samples/sec#011loss=5.696152\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1116.0449981689453, \"sum\": 1116.0449981689453, \"min\": 1116.0449981689453}}, \"EndTime\": 1517703705.767934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703704.637624}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:45 INFO 140150847625024] Epoch[65] Batch[0] avg_epoch_loss=5.757907\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] Epoch[65] Batch[5] avg_epoch_loss=5.695616\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] Epoch[65] Batch [5]#011Speed: 343.23 samples/sec#011loss=5.695616\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] Epoch[65] Batch[10] avg_epoch_loss=5.676997\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] Epoch[65] Batch [10]#011Speed: 287.35 samples/sec#011loss=5.654653\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1163.4409427642822, \"sum\": 1163.4409427642822, \"min\": 1163.4409427642822}}, \"EndTime\": 1517703706.950095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703705.768001}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:46 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8fcecb35-8451-476b-be90-2ef3534815b5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.35906982421875, \"sum\": 13.35906982421875, \"min\": 13.35906982421875}}, \"EndTime\": 1517703706.963669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703706.950159}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:47 INFO 140150847625024] Epoch[66] Batch[0] avg_epoch_loss=5.695165\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:47 INFO 140150847625024] Epoch[66] Batch[5] avg_epoch_loss=5.669061\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:47 INFO 140150847625024] Epoch[66] Batch [5]#011Speed: 252.80 samples/sec#011loss=5.669061\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] Epoch[66] Batch[10] avg_epoch_loss=5.659138\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] Epoch[66] Batch [10]#011Speed: 345.51 samples/sec#011loss=5.647231\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.1159362792969, \"sum\": 1282.1159362792969, \"min\": 1282.1159362792969}}, \"EndTime\": 1517703708.25798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703706.963719}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ee4b169d-4884-453a-ae8e-321de3a11e54-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.527870178222656, \"sum\": 13.527870178222656, \"min\": 13.527870178222656}}, \"EndTime\": 1517703708.271698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703708.258039}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] Epoch[67] Batch[0] avg_epoch_loss=5.650450\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] Epoch[67] Batch[5] avg_epoch_loss=5.652115\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:48 INFO 140150847625024] Epoch[67] Batch [5]#011Speed: 286.82 samples/sec#011loss=5.652115\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:21:49 INFO 140150847625024] Epoch[67] Batch[10] avg_epoch_loss=5.644648\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:49 INFO 140150847625024] Epoch[67] Batch [10]#011Speed: 356.28 samples/sec#011loss=5.635688\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:49 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1044.6109771728516, \"sum\": 1044.6109771728516, \"min\": 1044.6109771728516}}, \"EndTime\": 1517703709.328296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703708.271743}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:49 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:49 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_b54c9a18-1212-48e9-96bb-c0daa30744ec-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 72.0059871673584, \"sum\": 72.0059871673584, \"min\": 72.0059871673584}}, \"EndTime\": 1517703709.400588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703709.328398}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:49 INFO 140150847625024] Epoch[68] Batch[0] avg_epoch_loss=5.647789\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] Epoch[68] Batch[5] avg_epoch_loss=5.626750\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] Epoch[68] Batch [5]#011Speed: 310.72 samples/sec#011loss=5.626750\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] Epoch[68] Batch[10] avg_epoch_loss=5.630984\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] Epoch[68] Batch [10]#011Speed: 253.77 samples/sec#011loss=5.636065\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1266.9479846954346, \"sum\": 1266.9479846954346, \"min\": 1266.9479846954346}}, \"EndTime\": 1517703710.680992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703709.400646}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_4a50e2dd-4383-4d47-8e12-ea3a7f938b6e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.696121215820312, \"sum\": 14.696121215820312, \"min\": 14.696121215820312}}, \"EndTime\": 1517703710.695862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703710.68104}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:50 INFO 140150847625024] Epoch[69] Batch[0] avg_epoch_loss=5.667262\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:51 INFO 140150847625024] Epoch[69] Batch[5] avg_epoch_loss=5.661251\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:51 INFO 140150847625024] Epoch[69] Batch [5]#011Speed: 271.93 samples/sec#011loss=5.661251\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:51 INFO 140150847625024] Epoch[69] Batch[10] avg_epoch_loss=5.648870\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:51 INFO 140150847625024] Epoch[69] Batch [10]#011Speed: 322.93 samples/sec#011loss=5.634011\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:51 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1271.4800834655762, \"sum\": 1271.4800834655762, \"min\": 1271.4800834655762}}, \"EndTime\": 1517703711.979781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703710.695917}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:51 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:52 INFO 140150847625024] Epoch[70] Batch[0] avg_epoch_loss=5.689548\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:52 INFO 140150847625024] Epoch[70] Batch[5] avg_epoch_loss=5.674247\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:52 INFO 140150847625024] Epoch[70] Batch [5]#011Speed: 282.66 samples/sec#011loss=5.674247\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:53 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1014.0969753265381, \"sum\": 1014.0969753265381, \"min\": 1014.0969753265381}}, \"EndTime\": 1517703713.0095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703711.979846}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:53 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:53 INFO 140150847625024] Epoch[71] Batch[0] avg_epoch_loss=5.643203\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:53 INFO 140150847625024] Epoch[71] Batch[5] avg_epoch_loss=5.653830\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:53 INFO 140150847625024] Epoch[71] Batch [5]#011Speed: 272.68 samples/sec#011loss=5.653830\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] Epoch[71] Batch[10] avg_epoch_loss=5.650055\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] Epoch[71] Batch [10]#011Speed: 335.76 samples/sec#011loss=5.645525\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1118.7150478363037, \"sum\": 1118.7150478363037, \"min\": 1118.7150478363037}}, \"EndTime\": 1517703714.143627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703713.009576}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] Epoch[72] Batch[0] avg_epoch_loss=5.635742\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] Epoch[72] Batch[5] avg_epoch_loss=5.618749\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:54 INFO 140150847625024] Epoch[72] Batch [5]#011Speed: 334.28 samples/sec#011loss=5.618749\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:55 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 997.952938079834, \"sum\": 997.952938079834, \"min\": 997.952938079834}}, \"EndTime\": 1517703715.15708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703714.143682}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:55 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:55 INFO 140150847625024] Epoch[73] Batch[0] avg_epoch_loss=5.652716\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:55 INFO 140150847625024] Epoch[73] Batch[5] avg_epoch_loss=5.599138\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:55 INFO 140150847625024] Epoch[73] Batch [5]#011Speed: 319.07 samples/sec#011loss=5.599138\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:56 INFO 140150847625024] Epoch[73] Batch[10] avg_epoch_loss=5.608160\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:56 INFO 140150847625024] Epoch[73] Batch [10]#011Speed: 264.18 samples/sec#011loss=5.618987\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:56 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1252.432107925415, \"sum\": 1252.432107925415, \"min\": 1252.432107925415}}, \"EndTime\": 1517703716.427061, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703715.157146}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:56 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:56 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_6bb8905c-5852-4cc8-b4ea-982349234567-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.541936874389648, \"sum\": 13.541936874389648, \"min\": 13.541936874389648}}, \"EndTime\": 1517703716.440814, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703716.427123}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:56 INFO 140150847625024] Epoch[74] Batch[0] avg_epoch_loss=5.562709\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] Epoch[74] Batch[5] avg_epoch_loss=5.638848\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] Epoch[74] Batch [5]#011Speed: 269.13 samples/sec#011loss=5.638848\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] Epoch[74] Batch[10] avg_epoch_loss=5.633534\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] Epoch[74] Batch [10]#011Speed: 337.86 samples/sec#011loss=5.627158\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1110.687017440796, \"sum\": 1110.687017440796, \"min\": 1110.687017440796}}, \"EndTime\": 1517703717.563914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703716.440861}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:57 INFO 140150847625024] Epoch[75] Batch[0] avg_epoch_loss=5.702504\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:58 INFO 140150847625024] Epoch[75] Batch[5] avg_epoch_loss=5.599016\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:58 INFO 140150847625024] Epoch[75] Batch [5]#011Speed: 340.63 samples/sec#011loss=5.599016\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:58 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1005.9680938720703, \"sum\": 1005.9680938720703, \"min\": 1005.9680938720703}}, \"EndTime\": 1517703718.587014, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703717.563976}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:58 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:58 INFO 140150847625024] Epoch[76] Batch[0] avg_epoch_loss=5.716398\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:21:59 INFO 140150847625024] Epoch[76] Batch[5] avg_epoch_loss=5.632205\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:59 INFO 140150847625024] Epoch[76] Batch [5]#011Speed: 354.12 samples/sec#011loss=5.632205\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:59 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 991.1320209503174, \"sum\": 991.1320209503174, \"min\": 991.1320209503174}}, \"EndTime\": 1517703719.594973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703718.58708}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:59 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:21:59 INFO 140150847625024] Epoch[77] Batch[0] avg_epoch_loss=5.692561\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] Epoch[77] Batch[5] avg_epoch_loss=5.624525\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] Epoch[77] Batch [5]#011Speed: 340.74 samples/sec#011loss=5.624525\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] Epoch[77] Batch[10] avg_epoch_loss=10.403262\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] Epoch[77] Batch [10]#011Speed: 293.22 samples/sec#011loss=16.137746\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1175.1351356506348, \"sum\": 1175.1351356506348, \"min\": 1175.1351356506348}}, \"EndTime\": 1517703720.783241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703719.595038}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:00 INFO 140150847625024] Epoch[78] Batch[0] avg_epoch_loss=5.701787\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:01 INFO 140150847625024] Epoch[78] Batch[5] avg_epoch_loss=23.749004\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:01 INFO 140150847625024] Epoch[78] Batch [5]#011Speed: 266.65 samples/sec#011loss=23.749004\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:01 INFO 140150847625024] Epoch[78] Batch[10] avg_epoch_loss=15.488922\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:01 INFO 140150847625024] Epoch[78] Batch [10]#011Speed: 357.25 samples/sec#011loss=5.576823\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:01 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1090.1930332183838, \"sum\": 1090.1930332183838, \"min\": 1090.1930332183838}}, \"EndTime\": 1517703721.885673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703720.783317}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:01 INFO 140150847625024] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:02 INFO 140150847625024] Epoch[79] Batch[0] avg_epoch_loss=5.587558\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:02 INFO 140150847625024] Epoch[79] Batch[5] avg_epoch_loss=5.594027\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:02 INFO 140150847625024] Epoch[79] Batch [5]#011Speed: 314.17 samples/sec#011loss=5.594027\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] Epoch[79] Batch[10] avg_epoch_loss=5.585531\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] Epoch[79] Batch [10]#011Speed: 284.04 samples/sec#011loss=5.575335\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1198.390007019043, \"sum\": 1198.390007019043, \"min\": 1198.390007019043}}, \"EndTime\": 1517703723.100463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703721.885743}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ee7b7f55-6a43-471f-b0aa-652fc4284d4d-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.059854507446289, \"sum\": 13.059854507446289, \"min\": 13.059854507446289}}, \"EndTime\": 1517703723.113714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703723.100516}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] Epoch[80] Batch[0] avg_epoch_loss=5.626723\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] Epoch[80] Batch[5] avg_epoch_loss=5.629505\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:03 INFO 140150847625024] Epoch[80] Batch [5]#011Speed: 265.02 samples/sec#011loss=5.629505\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:04 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1015.0160789489746, \"sum\": 1015.0160789489746, \"min\": 1015.0160789489746}}, \"EndTime\": 1517703724.141056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703723.113754}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:04 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:04 INFO 140150847625024] Epoch[81] Batch[0] avg_epoch_loss=5.724586\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:04 INFO 140150847625024] Epoch[81] Batch[5] avg_epoch_loss=5.597557\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:04 INFO 140150847625024] Epoch[81] Batch [5]#011Speed: 284.87 samples/sec#011loss=5.597557\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] Epoch[81] Batch[10] avg_epoch_loss=5.595278\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] Epoch[81] Batch [10]#011Speed: 322.31 samples/sec#011loss=5.592544\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1099.0500450134277, \"sum\": 1099.0500450134277, \"min\": 1099.0500450134277}}, \"EndTime\": 1517703725.251319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703724.141116}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] Epoch[82] Batch[0] avg_epoch_loss=5.596618\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] Epoch[82] Batch[5] avg_epoch_loss=5.592012\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:05 INFO 140150847625024] Epoch[82] Batch [5]#011Speed: 337.12 samples/sec#011loss=5.592012\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:06 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 997.1718788146973, \"sum\": 997.1718788146973, \"min\": 997.1718788146973}}, \"EndTime\": 1517703726.265824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703725.251382}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:06 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:06 INFO 140150847625024] Epoch[83] Batch[0] avg_epoch_loss=5.629855\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:06 INFO 140150847625024] Epoch[83] Batch[5] avg_epoch_loss=5.578562\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:06 INFO 140150847625024] Epoch[83] Batch [5]#011Speed: 344.62 samples/sec#011loss=5.578562\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:07 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1042.306900024414, \"sum\": 1042.306900024414, \"min\": 1042.306900024414}}, \"EndTime\": 1517703727.326842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703726.265894}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:07 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:07 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_b342d8bb-9f8d-4217-b3ca-2a4e4ef87f30-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 75.32715797424316, \"sum\": 75.32715797424316, \"min\": 75.32715797424316}}, \"EndTime\": 1517703727.402372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703727.3269}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:07 INFO 140150847625024] Epoch[84] Batch[0] avg_epoch_loss=5.593851\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:08 INFO 140150847625024] Epoch[84] Batch[5] avg_epoch_loss=5.609829\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:08 INFO 140150847625024] Epoch[84] Batch [5]#011Speed: 317.98 samples/sec#011loss=5.609829\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:08 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1013.6950016021729, \"sum\": 1013.6950016021729, \"min\": 1013.6950016021729}}, \"EndTime\": 1517703728.43076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703727.402428}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:08 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:08 INFO 140150847625024] Epoch[85] Batch[0] avg_epoch_loss=5.639438\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:22:09 INFO 140150847625024] Epoch[85] Batch[5] avg_epoch_loss=5.561104\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:09 INFO 140150847625024] Epoch[85] Batch [5]#011Speed: 358.87 samples/sec#011loss=5.561104\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:09 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 994.0390586853027, \"sum\": 994.0390586853027, \"min\": 994.0390586853027}}, \"EndTime\": 1517703729.445624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703728.430836}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:09 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:09 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_803ced77-59fa-436c-a840-a91c0d60728d-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 55.73010444641113, \"sum\": 55.73010444641113, \"min\": 55.73010444641113}}, \"EndTime\": 1517703729.501597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703729.445691}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:09 INFO 140150847625024] Epoch[86] Batch[0] avg_epoch_loss=112.864029\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:10 INFO 140150847625024] Epoch[86] Batch[5] avg_epoch_loss=23.442060\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:10 INFO 140150847625024] Epoch[86] Batch [5]#011Speed: 337.75 samples/sec#011loss=23.442060\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:10 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 997.4081516265869, \"sum\": 997.4081516265869, \"min\": 997.4081516265869}}, \"EndTime\": 1517703730.511186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703729.501641}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:10 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:10 INFO 140150847625024] Epoch[87] Batch[0] avg_epoch_loss=5.498742\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:11 INFO 140150847625024] Epoch[87] Batch[5] avg_epoch_loss=5.536529\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:11 INFO 140150847625024] Epoch[87] Batch [5]#011Speed: 317.86 samples/sec#011loss=5.536529\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:11 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1031.3758850097656, \"sum\": 1031.3758850097656, \"min\": 1031.3758850097656}}, \"EndTime\": 1517703731.558691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703730.511253}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:11 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:11 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_7f5896bf-4e73-42ba-8cb6-3c22264829e9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 50.16303062438965, \"sum\": 50.16303062438965, \"min\": 50.16303062438965}}, \"EndTime\": 1517703731.609079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703731.55875}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:11 INFO 140150847625024] Epoch[88] Batch[0] avg_epoch_loss=5.530507\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] Epoch[88] Batch[5] avg_epoch_loss=5.558391\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] Epoch[88] Batch [5]#011Speed: 335.20 samples/sec#011loss=5.558391\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] Epoch[88] Batch[10] avg_epoch_loss=5.549996\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] Epoch[88] Batch [10]#011Speed: 252.28 samples/sec#011loss=5.539923\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1200.3350257873535, \"sum\": 1200.3350257873535, \"min\": 1200.3350257873535}}, \"EndTime\": 1517703732.824276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703731.609119}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:12 INFO 140150847625024] Epoch[89] Batch[0] avg_epoch_loss=5.607585\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:13 INFO 140150847625024] Epoch[89] Batch[5] avg_epoch_loss=5.538533\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:13 INFO 140150847625024] Epoch[89] Batch [5]#011Speed: 252.55 samples/sec#011loss=5.538533\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:13 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1122.4279403686523, \"sum\": 1122.4279403686523, \"min\": 1122.4279403686523}}, \"EndTime\": 1517703733.961784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703732.824404}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:13 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:14 INFO 140150847625024] Epoch[90] Batch[0] avg_epoch_loss=5.483002\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:14 INFO 140150847625024] Epoch[90] Batch[5] avg_epoch_loss=5.503432\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:14 INFO 140150847625024] Epoch[90] Batch [5]#011Speed: 255.70 samples/sec#011loss=5.503432\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] Epoch[90] Batch[10] avg_epoch_loss=5.511063\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] Epoch[90] Batch [10]#011Speed: 354.85 samples/sec#011loss=5.520220\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1129.1680335998535, \"sum\": 1129.1680335998535, \"min\": 1129.1680335998535}}, \"EndTime\": 1517703735.104255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703733.96185}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8ded2e07-847f-481b-9c4c-f548bb239374-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.08405303955078, \"sum\": 64.08405303955078, \"min\": 64.08405303955078}}, \"EndTime\": 1517703735.16861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703735.104361}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] Epoch[91] Batch[0] avg_epoch_loss=5.539676\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] Epoch[91] Batch[5] avg_epoch_loss=5.518452\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:15 INFO 140150847625024] Epoch[91] Batch [5]#011Speed: 329.52 samples/sec#011loss=5.518452\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:16 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1002.4189949035645, \"sum\": 1002.4189949035645, \"min\": 1002.4189949035645}}, \"EndTime\": 1517703736.184421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703735.168668}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:16 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:16 INFO 140150847625024] Epoch[92] Batch[0] avg_epoch_loss=5.556924\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:16 INFO 140150847625024] Epoch[92] Batch[5] avg_epoch_loss=5.520932\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:16 INFO 140150847625024] Epoch[92] Batch [5]#011Speed: 370.82 samples/sec#011loss=5.520932\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] Epoch[92] Batch[10] avg_epoch_loss=5.499754\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] Epoch[92] Batch [10]#011Speed: 276.75 samples/sec#011loss=5.474342\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1154.533863067627, \"sum\": 1154.533863067627, \"min\": 1154.533863067627}}, \"EndTime\": 1517703737.358323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703736.18449}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_c20bf62d-1915-41d3-b817-14f4ac78d053-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.027191162109375, \"sum\": 13.027191162109375, \"min\": 13.027191162109375}}, \"EndTime\": 1517703737.371546, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703737.358383}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] Epoch[93] Batch[0] avg_epoch_loss=5.583395\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] Epoch[93] Batch[5] avg_epoch_loss=5.531017\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:17 INFO 140150847625024] Epoch[93] Batch [5]#011Speed: 283.78 samples/sec#011loss=5.531017\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:18 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1049.6180057525635, \"sum\": 1049.6180057525635, \"min\": 1049.6180057525635}}, \"EndTime\": 1517703738.435911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703737.37159}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:18 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:18 INFO 140150847625024] Epoch[94] Batch[0] avg_epoch_loss=5.493086\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:19 INFO 140150847625024] Epoch[94] Batch[5] avg_epoch_loss=5.493256\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:19 INFO 140150847625024] Epoch[94] Batch [5]#011Speed: 317.69 samples/sec#011loss=5.493256\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:22:19 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 969.6381092071533, \"sum\": 969.6381092071533, \"min\": 969.6381092071533}}, \"EndTime\": 1517703739.420764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703738.43597}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:19 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:19 INFO 140150847625024] Epoch[95] Batch[0] avg_epoch_loss=5.706317\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:20 INFO 140150847625024] Epoch[95] Batch[5] avg_epoch_loss=5.485696\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:20 INFO 140150847625024] Epoch[95] Batch [5]#011Speed: 285.82 samples/sec#011loss=5.485696\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:20 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1044.6491241455078, \"sum\": 1044.6491241455078, \"min\": 1044.6491241455078}}, \"EndTime\": 1517703740.480644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703739.420842}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:20 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:20 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8cfabeb5-0e81-4c7a-811a-6fc9902dbcb9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.022111892700195, \"sum\": 14.022111892700195, \"min\": 14.022111892700195}}, \"EndTime\": 1517703740.494891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703740.480706}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:20 INFO 140150847625024] Epoch[96] Batch[0] avg_epoch_loss=5.490191\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] Epoch[96] Batch[5] avg_epoch_loss=5.514654\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] Epoch[96] Batch [5]#011Speed: 288.67 samples/sec#011loss=5.514654\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] Epoch[96] Batch[10] avg_epoch_loss=15.023042\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] Epoch[96] Batch [10]#011Speed: 333.43 samples/sec#011loss=26.433106\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1073.1821060180664, \"sum\": 1073.1821060180664, \"min\": 1073.1821060180664}}, \"EndTime\": 1517703741.583505, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703740.49494}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:21 INFO 140150847625024] Epoch[97] Batch[0] avg_epoch_loss=5.464828\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:22 INFO 140150847625024] Epoch[97] Batch[5] avg_epoch_loss=5.487566\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:22 INFO 140150847625024] Epoch[97] Batch [5]#011Speed: 344.26 samples/sec#011loss=5.487566\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:22 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1023.8299369812012, \"sum\": 1023.8299369812012, \"min\": 1023.8299369812012}}, \"EndTime\": 1517703742.621872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703741.583556}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:22 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:22 INFO 140150847625024] Epoch[98] Batch[0] avg_epoch_loss=5.504603\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:23 INFO 140150847625024] Epoch[98] Batch[5] avg_epoch_loss=5.494410\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:23 INFO 140150847625024] Epoch[98] Batch [5]#011Speed: 340.86 samples/sec#011loss=5.494410\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:23 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 992.9001331329346, \"sum\": 992.9001331329346, \"min\": 992.9001331329346}}, \"EndTime\": 1517703743.632845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703742.621952}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:23 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:23 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_f2d589a6-7dfe-4a31-9b37-33c46ea8fa86-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 53.79199981689453, \"sum\": 53.79199981689453, \"min\": 53.79199981689453}}, \"EndTime\": 1517703743.686829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703743.632898}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:23 INFO 140150847625024] Epoch[99] Batch[0] avg_epoch_loss=5.488508\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:24 INFO 140150847625024] Epoch[99] Batch[5] avg_epoch_loss=5.482544\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:24 INFO 140150847625024] Epoch[99] Batch [5]#011Speed: 309.69 samples/sec#011loss=5.482544\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:24 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1051.6579151153564, \"sum\": 1051.6579151153564, \"min\": 1051.6579151153564}}, \"EndTime\": 1517703744.751561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703743.686882}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:24 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:24 INFO 140150847625024] Epoch[100] Batch[0] avg_epoch_loss=5.566166\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:25 INFO 140150847625024] Epoch[100] Batch[5] avg_epoch_loss=5.494129\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:25 INFO 140150847625024] Epoch[100] Batch [5]#011Speed: 320.36 samples/sec#011loss=5.494129\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:25 INFO 140150847625024] processed a total of 288 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 985.1491451263428, \"sum\": 985.1491451263428, \"min\": 985.1491451263428}}, \"EndTime\": 1517703745.752374, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703744.751626}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:25 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:25 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_39a72b24-83f6-4652-be74-39b113d90543-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.520956039428711, \"sum\": 13.520956039428711, \"min\": 13.520956039428711}}, \"EndTime\": 1517703745.766118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703745.752441}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:25 INFO 140150847625024] Epoch[101] Batch[0] avg_epoch_loss=5.458460\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] Epoch[101] Batch[5] avg_epoch_loss=5.475726\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] Epoch[101] Batch [5]#011Speed: 267.42 samples/sec#011loss=5.475726\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] Epoch[101] Batch[10] avg_epoch_loss=5.468456\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] Epoch[101] Batch [10]#011Speed: 351.28 samples/sec#011loss=5.459733\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1102.0081043243408, \"sum\": 1102.0081043243408, \"min\": 1102.0081043243408}}, \"EndTime\": 1517703746.880652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703745.766164}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:26 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_6cffe402-6adb-48c2-931b-51b015894a40-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 56.96392059326172, \"sum\": 56.96392059326172, \"min\": 56.96392059326172}}, \"EndTime\": 1517703746.93787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703746.880724}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:27 INFO 140150847625024] Epoch[102] Batch[0] avg_epoch_loss=5.518199\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:27 INFO 140150847625024] Epoch[102] Batch[5] avg_epoch_loss=5.466789\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:27 INFO 140150847625024] Epoch[102] Batch [5]#011Speed: 336.60 samples/sec#011loss=5.466789\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] Epoch[102] Batch[10] avg_epoch_loss=5.454678\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] Epoch[102] Batch [10]#011Speed: 264.91 samples/sec#011loss=5.440144\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1200.5248069763184, \"sum\": 1200.5248069763184, \"min\": 1200.5248069763184}}, \"EndTime\": 1517703748.151493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703746.937929}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_e7a287eb-801c-4dcd-9b95-e9aca7bb6a9b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.609886169433594, \"sum\": 13.609886169433594, \"min\": 13.609886169433594}}, \"EndTime\": 1517703748.165314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703748.151555}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] Epoch[103] Batch[0] avg_epoch_loss=5.478088\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] Epoch[103] Batch[5] avg_epoch_loss=5.449442\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:28 INFO 140150847625024] Epoch[103] Batch [5]#011Speed: 287.95 samples/sec#011loss=5.449442\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] Epoch[103] Batch[10] avg_epoch_loss=5.438404\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] Epoch[103] Batch [10]#011Speed: 358.94 samples/sec#011loss=5.425158\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1046.293020248413, \"sum\": 1046.293020248413, \"min\": 1046.293020248413}}, \"EndTime\": 1517703749.225707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703748.16536}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8b1c5f32-ccec-4c14-a892-d439adef90da-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.76495552062988, \"sum\": 61.76495552062988, \"min\": 61.76495552062988}}, \"EndTime\": 1517703749.287725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703749.225777}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] Epoch[104] Batch[0] avg_epoch_loss=5.510117\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] Epoch[104] Batch[5] avg_epoch_loss=22.641756\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:29 INFO 140150847625024] Epoch[104] Batch [5]#011Speed: 350.24 samples/sec#011loss=22.641756\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:30 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 991.8158054351807, \"sum\": 991.8158054351807, \"min\": 991.8158054351807}}, \"EndTime\": 1517703750.291595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703749.287769}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:30 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:30 INFO 140150847625024] Epoch[105] Batch[0] avg_epoch_loss=5.516412\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:30 INFO 140150847625024] Epoch[105] Batch[5] avg_epoch_loss=5.450933\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:30 INFO 140150847625024] Epoch[105] Batch [5]#011Speed: 336.69 samples/sec#011loss=5.450933\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:31 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1011.5280151367188, \"sum\": 1011.5280151367188, \"min\": 1011.5280151367188}}, \"EndTime\": 1517703751.319411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703750.291657}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:31 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:31 INFO 140150847625024] Epoch[106] Batch[0] avg_epoch_loss=5.579997\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:31 INFO 140150847625024] Epoch[106] Batch[5] avg_epoch_loss=5.454496\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:31 INFO 140150847625024] Epoch[106] Batch [5]#011Speed: 351.99 samples/sec#011loss=5.454496\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:32 INFO 140150847625024] Epoch[106] Batch[10] avg_epoch_loss=5.434604\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:32 INFO 140150847625024] Epoch[106] Batch [10]#011Speed: 278.09 samples/sec#011loss=5.410733\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:32 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1154.3810367584229, \"sum\": 1154.3810367584229, \"min\": 1154.3810367584229}}, \"EndTime\": 1517703752.488942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703751.319496}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:32 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:32 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5e682583-77b0-4f77-a4ca-27fb7cc31ab5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.859033584594727, \"sum\": 13.859033584594727, \"min\": 13.859033584594727}}, \"EndTime\": 1517703752.503001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703752.48901}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:32 INFO 140150847625024] Epoch[107] Batch[0] avg_epoch_loss=5.407639\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] Epoch[107] Batch[5] avg_epoch_loss=5.436121\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] Epoch[107] Batch [5]#011Speed: 282.97 samples/sec#011loss=5.436121\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] Epoch[107] Batch[10] avg_epoch_loss=5.421956\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] Epoch[107] Batch [10]#011Speed: 356.07 samples/sec#011loss=5.404958\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1057.589054107666, \"sum\": 1057.589054107666, \"min\": 1057.589054107666}}, \"EndTime\": 1517703753.574859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703752.503047}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_9ef2fad4-bdbf-4307-b196-ac17bfdf29c4-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 52.29496955871582, \"sum\": 52.29496955871582, \"min\": 52.29496955871582}}, \"EndTime\": 1517703753.627422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703753.574921}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:33 INFO 140150847625024] Epoch[108] Batch[0] avg_epoch_loss=5.449096\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] Epoch[108] Batch[5] avg_epoch_loss=5.396837\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] Epoch[108] Batch [5]#011Speed: 341.30 samples/sec#011loss=5.396837\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] Epoch[108] Batch[10] avg_epoch_loss=5.405754\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] Epoch[108] Batch [10]#011Speed: 295.53 samples/sec#011loss=5.416455\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1104.9258708953857, \"sum\": 1104.9258708953857, \"min\": 1104.9258708953857}}, \"EndTime\": 1517703754.747023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703753.627471}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_61040b3d-229e-40e3-87b7-5001b2c7cc2e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.812946319580078, \"sum\": 14.812946319580078, \"min\": 14.812946319580078}}, \"EndTime\": 1517703754.762093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703754.747099}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:34 INFO 140150847625024] Epoch[109] Batch[0] avg_epoch_loss=5.433795\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:35 INFO 140150847625024] Epoch[109] Batch[5] avg_epoch_loss=5.423464\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:35 INFO 140150847625024] Epoch[109] Batch [5]#011Speed: 273.32 samples/sec#011loss=5.423464\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:35 INFO 140150847625024] processed a total of 288 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 884.9380016326904, \"sum\": 884.9380016326904, \"min\": 884.9380016326904}}, \"EndTime\": 1517703755.658962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703754.762153}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:35 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:35 INFO 140150847625024] Epoch[110] Batch[0] avg_epoch_loss=5.566373\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] Epoch[110] Batch[5] avg_epoch_loss=5.445093\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] Epoch[110] Batch [5]#011Speed: 344.60 samples/sec#011loss=5.445093\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] Epoch[110] Batch[10] avg_epoch_loss=5.424977\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] Epoch[110] Batch [10]#011Speed: 290.19 samples/sec#011loss=5.400837\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1143.4261798858643, \"sum\": 1143.4261798858643, \"min\": 1143.4261798858643}}, \"EndTime\": 1517703756.819149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703755.659023}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:36 INFO 140150847625024] Epoch[111] Batch[0] avg_epoch_loss=5.506446\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] Epoch[111] Batch[5] avg_epoch_loss=5.461162\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] Epoch[111] Batch [5]#011Speed: 287.63 samples/sec#011loss=5.461162\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] Epoch[111] Batch[10] avg_epoch_loss=5.401749\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] Epoch[111] Batch [10]#011Speed: 351.62 samples/sec#011loss=5.330454\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1064.4910335540771, \"sum\": 1064.4910335540771, \"min\": 1064.4910335540771}}, \"EndTime\": 1517703757.899171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703756.819223}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:37 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_69554d26-32d0-4f40-81b3-83281c0d730c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.12318420410156, \"sum\": 57.12318420410156, \"min\": 57.12318420410156}}, \"EndTime\": 1517703757.956582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703757.899261}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:38 INFO 140150847625024] Epoch[112] Batch[0] avg_epoch_loss=5.432100\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:38 INFO 140150847625024] Epoch[112] Batch[5] avg_epoch_loss=5.425947\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:38 INFO 140150847625024] Epoch[112] Batch [5]#011Speed: 350.51 samples/sec#011loss=5.425947\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:38 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 953.3979892730713, \"sum\": 953.3979892730713, \"min\": 953.3979892730713}}, \"EndTime\": 1517703758.925074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703757.956641}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:38 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:22:39 INFO 140150847625024] Epoch[113] Batch[0] avg_epoch_loss=5.480984\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:39 INFO 140150847625024] Epoch[113] Batch[5] avg_epoch_loss=5.418650\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:39 INFO 140150847625024] Epoch[113] Batch [5]#011Speed: 339.01 samples/sec#011loss=5.418650\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:39 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 982.0148944854736, \"sum\": 982.0148944854736, \"min\": 982.0148944854736}}, \"EndTime\": 1517703759.919776, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703758.925123}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:39 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:40 INFO 140150847625024] Epoch[114] Batch[0] avg_epoch_loss=5.400302\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:40 INFO 140150847625024] Epoch[114] Batch[5] avg_epoch_loss=5.378047\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:40 INFO 140150847625024] Epoch[114] Batch [5]#011Speed: 340.35 samples/sec#011loss=5.378047\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] Epoch[114] Batch[10] avg_epoch_loss=5.372630\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] Epoch[114] Batch [10]#011Speed: 300.00 samples/sec#011loss=5.366130\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1155.1620960235596, \"sum\": 1155.1620960235596, \"min\": 1155.1620960235596}}, \"EndTime\": 1517703761.088526, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703759.919841}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_0d4ed151-7468-4472-9a9e-b655c0eee04f-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.711214065551758, \"sum\": 13.711214065551758, \"min\": 13.711214065551758}}, \"EndTime\": 1517703761.102401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703761.088575}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] Epoch[115] Batch[0] avg_epoch_loss=5.373739\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] Epoch[115] Batch[5] avg_epoch_loss=5.391004\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:41 INFO 140150847625024] Epoch[115] Batch [5]#011Speed: 281.18 samples/sec#011loss=5.391004\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:42 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1016.6211128234863, \"sum\": 1016.6211128234863, \"min\": 1016.6211128234863}}, \"EndTime\": 1517703762.131196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703761.102438}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:42 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:42 INFO 140150847625024] Epoch[116] Batch[0] avg_epoch_loss=5.451589\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:42 INFO 140150847625024] Epoch[116] Batch[5] avg_epoch_loss=5.401664\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:42 INFO 140150847625024] Epoch[116] Batch [5]#011Speed: 283.49 samples/sec#011loss=5.401664\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] Epoch[116] Batch[10] avg_epoch_loss=5.392313\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] Epoch[116] Batch [10]#011Speed: 357.67 samples/sec#011loss=5.381092\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1070.112943649292, \"sum\": 1070.112943649292, \"min\": 1070.112943649292}}, \"EndTime\": 1517703763.213169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703762.131261}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] Epoch[117] Batch[0] avg_epoch_loss=5.392192\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] Epoch[117] Batch[5] avg_epoch_loss=5.350144\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:43 INFO 140150847625024] Epoch[117] Batch [5]#011Speed: 337.30 samples/sec#011loss=5.350144\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:44 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1044.2569255828857, \"sum\": 1044.2569255828857, \"min\": 1044.2569255828857}}, \"EndTime\": 1517703764.27609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703763.213237}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:44 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:44 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_caf53adc-d8d4-48b2-8f36-597dcc1915d9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.2549991607666, \"sum\": 64.2549991607666, \"min\": 64.2549991607666}}, \"EndTime\": 1517703764.340575, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703764.276156}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:44 INFO 140150847625024] Epoch[118] Batch[0] avg_epoch_loss=5.369421\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:44 INFO 140150847625024] Epoch[118] Batch[5] avg_epoch_loss=5.366566\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:44 INFO 140150847625024] Epoch[118] Batch [5]#011Speed: 354.35 samples/sec#011loss=5.366566\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:45 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 970.6099033355713, \"sum\": 970.6099033355713, \"min\": 970.6099033355713}}, \"EndTime\": 1517703765.322739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703764.340628}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:45 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:45 INFO 140150847625024] Epoch[119] Batch[0] avg_epoch_loss=5.289493\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:45 INFO 140150847625024] Epoch[119] Batch[5] avg_epoch_loss=5.327280\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:45 INFO 140150847625024] Epoch[119] Batch [5]#011Speed: 334.51 samples/sec#011loss=5.327280\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:46 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1028.6400318145752, \"sum\": 1028.6400318145752, \"min\": 1028.6400318145752}}, \"EndTime\": 1517703766.364682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703765.322812}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:46 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:46 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_bd6e52cf-be66-4e1e-a487-e20f02248f8b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 51.603078842163086, \"sum\": 51.603078842163086, \"min\": 51.603078842163086}}, \"EndTime\": 1517703766.416541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703766.364755}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:46 INFO 140150847625024] Epoch[120] Batch[0] avg_epoch_loss=5.546933\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:46 INFO 140150847625024] Epoch[120] Batch[5] avg_epoch_loss=5.379516\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:46 INFO 140150847625024] Epoch[120] Batch [5]#011Speed: 360.99 samples/sec#011loss=5.379516\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:47 INFO 140150847625024] Epoch[120] Batch[10] avg_epoch_loss=5.337117\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:47 INFO 140150847625024] Epoch[120] Batch [10]#011Speed: 282.94 samples/sec#011loss=5.286239\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:47 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1117.8390979766846, \"sum\": 1117.8390979766846, \"min\": 1117.8390979766846}}, \"EndTime\": 1517703767.549593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703766.416613}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:47 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:47 INFO 140150847625024] Epoch[121] Batch[0] avg_epoch_loss=5.308802\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] Epoch[121] Batch[5] avg_epoch_loss=5.308620\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] Epoch[121] Batch [5]#011Speed: 270.24 samples/sec#011loss=5.308620\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] Epoch[121] Batch[10] avg_epoch_loss=5.306006\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] Epoch[121] Batch [10]#011Speed: 341.73 samples/sec#011loss=5.302869\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1109.9200248718262, \"sum\": 1109.9200248718262, \"min\": 1109.9200248718262}}, \"EndTime\": 1517703768.671298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703767.549657}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_3b7dccce-0c4f-4d57-a37f-b21ec45fccd9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.08703804016113, \"sum\": 59.08703804016113, \"min\": 59.08703804016113}}, \"EndTime\": 1517703768.730616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703768.671363}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:48 INFO 140150847625024] Epoch[122] Batch[0] avg_epoch_loss=5.293659\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:22:49 INFO 140150847625024] Epoch[122] Batch[5] avg_epoch_loss=5.297572\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:49 INFO 140150847625024] Epoch[122] Batch [5]#011Speed: 354.51 samples/sec#011loss=5.297572\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:49 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 957.495927810669, \"sum\": 957.495927810669, \"min\": 957.495927810669}}, \"EndTime\": 1517703769.700285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703768.730672}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:49 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:49 INFO 140150847625024] Epoch[123] Batch[0] avg_epoch_loss=5.373982\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] Epoch[123] Batch[5] avg_epoch_loss=5.322268\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] Epoch[123] Batch [5]#011Speed: 323.54 samples/sec#011loss=5.322268\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] Epoch[123] Batch[10] avg_epoch_loss=5.303869\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] Epoch[123] Batch [10]#011Speed: 291.95 samples/sec#011loss=5.281790\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1168.6499118804932, \"sum\": 1168.6499118804932, \"min\": 1168.6499118804932}}, \"EndTime\": 1517703770.882821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703769.700383}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_6a556837-c16f-4dbb-969c-153495a85531-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.59303092956543, \"sum\": 12.59303092956543, \"min\": 12.59303092956543}}, \"EndTime\": 1517703770.895579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703770.88287}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:50 INFO 140150847625024] Epoch[124] Batch[0] avg_epoch_loss=5.357462\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:51 INFO 140150847625024] Epoch[124] Batch[5] avg_epoch_loss=5.291868\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:51 INFO 140150847625024] Epoch[124] Batch [5]#011Speed: 283.83 samples/sec#011loss=5.291868\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:51 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1017.6348686218262, \"sum\": 1017.6348686218262, \"min\": 1017.6348686218262}}, \"EndTime\": 1517703771.924803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703770.895615}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:51 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:51 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_e102bc22-86a6-46cf-ace1-5291b80fd257-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.159917831420898, \"sum\": 14.159917831420898, \"min\": 14.159917831420898}}, \"EndTime\": 1517703771.939149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703771.924853}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:51 INFO 140150847625024] Epoch[125] Batch[0] avg_epoch_loss=5.299990\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:52 INFO 140150847625024] Epoch[125] Batch[5] avg_epoch_loss=5.303304\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:52 INFO 140150847625024] Epoch[125] Batch [5]#011Speed: 270.63 samples/sec#011loss=5.303304\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:52 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1010.4598999023438, \"sum\": 1010.4598999023438, \"min\": 1010.4598999023438}}, \"EndTime\": 1517703772.961104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703771.939193}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:52 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:52 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_e2273fe2-9c33-4181-895c-669f53c48896-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.125896453857422, \"sum\": 13.125896453857422, \"min\": 13.125896453857422}}, \"EndTime\": 1517703772.974411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703772.961155}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:53 INFO 140150847625024] Epoch[126] Batch[0] avg_epoch_loss=5.285014\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:53 INFO 140150847625024] Epoch[126] Batch[5] avg_epoch_loss=13.588607\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:53 INFO 140150847625024] Epoch[126] Batch [5]#011Speed: 305.24 samples/sec#011loss=13.588607\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] Epoch[126] Batch[10] avg_epoch_loss=19.017355\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] Epoch[126] Batch [10]#011Speed: 350.32 samples/sec#011loss=25.531853\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1020.0319290161133, \"sum\": 1020.0319290161133, \"min\": 1020.0319290161133}}, \"EndTime\": 1517703774.006547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703772.974455}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] Epoch[127] Batch[0] avg_epoch_loss=5.446495\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] Epoch[127] Batch[5] avg_epoch_loss=5.322105\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] Epoch[127] Batch [5]#011Speed: 341.99 samples/sec#011loss=5.322105\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 972.2959995269775, \"sum\": 972.2959995269775, \"min\": 972.2959995269775}}, \"EndTime\": 1517703774.99504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703774.006623}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:54 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:55 INFO 140150847625024] Epoch[128] Batch[0] avg_epoch_loss=5.262741\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:55 INFO 140150847625024] Epoch[128] Batch[5] avg_epoch_loss=5.288854\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:55 INFO 140150847625024] Epoch[128] Batch [5]#011Speed: 341.22 samples/sec#011loss=5.288854\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] Epoch[128] Batch[10] avg_epoch_loss=5.283683\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] Epoch[128] Batch [10]#011Speed: 285.89 samples/sec#011loss=5.277477\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1173.6600399017334, \"sum\": 1173.6600399017334, \"min\": 1173.6600399017334}}, \"EndTime\": 1517703776.185078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703774.995105}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] Epoch[129] Batch[0] avg_epoch_loss=5.369375\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] Epoch[129] Batch[5] avg_epoch_loss=5.314760\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:56 INFO 140150847625024] Epoch[129] Batch [5]#011Speed: 259.85 samples/sec#011loss=5.314760\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:57 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1096.5521335601807, \"sum\": 1096.5521335601807, \"min\": 1096.5521335601807}}, \"EndTime\": 1517703777.295093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703776.185139}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:57 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:57 INFO 140150847625024] Epoch[130] Batch[0] avg_epoch_loss=5.258649\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:57 INFO 140150847625024] Epoch[130] Batch[5] avg_epoch_loss=5.276838\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:57 INFO 140150847625024] Epoch[130] Batch [5]#011Speed: 285.85 samples/sec#011loss=5.276838\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:58 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1034.5220565795898, \"sum\": 1034.5220565795898, \"min\": 1034.5220565795898}}, \"EndTime\": 1517703778.341833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703777.295158}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:58 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:58 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_13a46995-3a7d-44bf-8dc2-f7f9e64aa832-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.248205184936523, \"sum\": 13.248205184936523, \"min\": 13.248205184936523}}, \"EndTime\": 1517703778.355278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703778.341896}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:58 INFO 140150847625024] Epoch[131] Batch[0] avg_epoch_loss=5.277798\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:58 INFO 140150847625024] Epoch[131] Batch[5] avg_epoch_loss=5.253047\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:58 INFO 140150847625024] Epoch[131] Batch [5]#011Speed: 326.38 samples/sec#011loss=5.253047\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:22:59 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 943.640947341919, \"sum\": 943.640947341919, \"min\": 943.640947341919}}, \"EndTime\": 1517703779.311108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703778.355322}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:59 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:59 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_11e21a29-d1bf-4666-8d27-52226c5b8432-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.785911560058594, \"sum\": 12.785911560058594, \"min\": 12.785911560058594}}, \"EndTime\": 1517703779.324091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703779.311159}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:59 INFO 140150847625024] Epoch[132] Batch[0] avg_epoch_loss=5.271626\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:59 INFO 140150847625024] Epoch[132] Batch[5] avg_epoch_loss=5.253470\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:22:59 INFO 140150847625024] Epoch[132] Batch [5]#011Speed: 285.92 samples/sec#011loss=5.253470\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:00 INFO 140150847625024] Epoch[132] Batch[10] avg_epoch_loss=5.250044\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:00 INFO 140150847625024] Epoch[132] Batch [10]#011Speed: 344.83 samples/sec#011loss=5.245934\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:00 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1067.4118995666504, \"sum\": 1067.4118995666504, \"min\": 1067.4118995666504}}, \"EndTime\": 1517703780.404118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703779.32413}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:00 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:00 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5e9a30f3-42d2-4e9c-b15d-3fc2ad8920ed-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.55885887145996, \"sum\": 69.55885887145996, \"min\": 69.55885887145996}}, \"EndTime\": 1517703780.473991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703780.404193}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:00 INFO 140150847625024] Epoch[133] Batch[0] avg_epoch_loss=5.178751\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:01 INFO 140150847625024] Epoch[133] Batch[5] avg_epoch_loss=5.215911\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:01 INFO 140150847625024] Epoch[133] Batch [5]#011Speed: 355.57 samples/sec#011loss=5.215911\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:01 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 907.8371524810791, \"sum\": 907.8371524810791, \"min\": 907.8371524810791}}, \"EndTime\": 1517703781.397255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703780.474059}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:01 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:01 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ada82e4f-fdbb-4f0c-9d27-6e673ea2cdb9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 51.245927810668945, \"sum\": 51.245927810668945, \"min\": 51.245927810668945}}, \"EndTime\": 1517703781.448747, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703781.397322}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:01 INFO 140150847625024] Epoch[134] Batch[0] avg_epoch_loss=5.318478\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] Epoch[134] Batch[5] avg_epoch_loss=5.244272\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] Epoch[134] Batch [5]#011Speed: 364.53 samples/sec#011loss=5.244272\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 913.0499362945557, \"sum\": 913.0499362945557, \"min\": 913.0499362945557}}, \"EndTime\": 1517703782.373502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703781.448809}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] Epoch[135] Batch[0] avg_epoch_loss=5.212874\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] Epoch[135] Batch[5] avg_epoch_loss=5.230644\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:02 INFO 140150847625024] Epoch[135] Batch [5]#011Speed: 362.79 samples/sec#011loss=5.230644\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:03 INFO 140150847625024] Epoch[135] Batch[10] avg_epoch_loss=5.227778\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:03 INFO 140150847625024] Epoch[135] Batch [10]#011Speed: 291.98 samples/sec#011loss=5.224339\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:03 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1126.6980171203613, \"sum\": 1126.6980171203613, \"min\": 1126.6980171203613}}, \"EndTime\": 1517703783.516019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703782.373565}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:03 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:03 INFO 140150847625024] Epoch[136] Batch[0] avg_epoch_loss=5.181052\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] Epoch[136] Batch[5] avg_epoch_loss=5.212441\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] Epoch[136] Batch [5]#011Speed: 281.31 samples/sec#011loss=5.212441\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] Epoch[136] Batch[10] avg_epoch_loss=5.198506\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] Epoch[136] Batch [10]#011Speed: 323.12 samples/sec#011loss=5.181783\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1268.5458660125732, \"sum\": 1268.5458660125732, \"min\": 1268.5458660125732}}, \"EndTime\": 1517703784.800013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703783.516093}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_17261162-522d-4a2d-9805-0ec881c23c0f-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.288021087646484, \"sum\": 13.288021087646484, \"min\": 13.288021087646484}}, \"EndTime\": 1517703784.813501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703784.800072}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:04 INFO 140150847625024] Epoch[137] Batch[0] avg_epoch_loss=5.160828\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:05 INFO 140150847625024] Epoch[137] Batch[5] avg_epoch_loss=5.159663\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:05 INFO 140150847625024] Epoch[137] Batch [5]#011Speed: 297.69 samples/sec#011loss=5.159663\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:05 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 981.5068244934082, \"sum\": 981.5068244934082, \"min\": 981.5068244934082}}, \"EndTime\": 1517703785.809596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703784.813546}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:05 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:05 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_f00096ad-90e3-449c-b194-ea273f58f967-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.355016708374023, \"sum\": 13.355016708374023, \"min\": 13.355016708374023}}, \"EndTime\": 1517703785.823133, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703785.809646}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:05 INFO 140150847625024] Epoch[138] Batch[0] avg_epoch_loss=5.263398\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:06 INFO 140150847625024] Epoch[138] Batch[5] avg_epoch_loss=5.192579\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:06 INFO 140150847625024] Epoch[138] Batch [5]#011Speed: 276.86 samples/sec#011loss=5.192579\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:06 INFO 140150847625024] Epoch[138] Batch[10] avg_epoch_loss=5.190843\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:06 INFO 140150847625024] Epoch[138] Batch [10]#011Speed: 365.89 samples/sec#011loss=5.188761\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:06 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1053.8959503173828, \"sum\": 1053.8959503173828, \"min\": 1053.8959503173828}}, \"EndTime\": 1517703786.889753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703785.823172}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:06 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:07 INFO 140150847625024] Epoch[139] Batch[0] avg_epoch_loss=5.171863\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:07 INFO 140150847625024] Epoch[139] Batch[5] avg_epoch_loss=5.171298\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:07 INFO 140150847625024] Epoch[139] Batch [5]#011Speed: 346.45 samples/sec#011loss=5.171298\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:07 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 972.6650714874268, \"sum\": 972.6650714874268, \"min\": 972.6650714874268}}, \"EndTime\": 1517703787.878606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703786.889826}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:07 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:07 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8ef89019-2c20-4fdc-ba9a-43c5ac466633-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.62691116333008, \"sum\": 61.62691116333008, \"min\": 61.62691116333008}}, \"EndTime\": 1517703787.940451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703787.87867}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:08 INFO 140150847625024] Epoch[140] Batch[0] avg_epoch_loss=5.192502\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:08 INFO 140150847625024] Epoch[140] Batch[5] avg_epoch_loss=5.212454\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:08 INFO 140150847625024] Epoch[140] Batch [5]#011Speed: 341.13 samples/sec#011loss=5.212454\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] Epoch[140] Batch[10] avg_epoch_loss=5.188674\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] Epoch[140] Batch [10]#011Speed: 282.61 samples/sec#011loss=5.160139\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1140.089988708496, \"sum\": 1140.089988708496, \"min\": 1140.089988708496}}, \"EndTime\": 1517703789.092648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703787.940493}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] Epoch[141] Batch[0] avg_epoch_loss=5.266460\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] Epoch[141] Batch[5] avg_epoch_loss=5.177835\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:09 INFO 140150847625024] Epoch[141] Batch [5]#011Speed: 281.80 samples/sec#011loss=5.177835\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] Epoch[141] Batch[10] avg_epoch_loss=5.159736\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] Epoch[141] Batch [10]#011Speed: 374.64 samples/sec#011loss=5.138018\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1035.6409549713135, \"sum\": 1035.6409549713135, \"min\": 1035.6409549713135}}, \"EndTime\": 1517703790.140454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703789.092708}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_dd7895d1-72ef-43b3-81ae-6eeee29007ca-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 77.50892639160156, \"sum\": 77.50892639160156, \"min\": 77.50892639160156}}, \"EndTime\": 1517703790.218204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703790.140521}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] Epoch[142] Batch[0] avg_epoch_loss=5.155268\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] Epoch[142] Batch[5] avg_epoch_loss=5.149323\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:10 INFO 140150847625024] Epoch[142] Batch [5]#011Speed: 358.16 samples/sec#011loss=5.149323\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:11 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 994.0991401672363, \"sum\": 994.0991401672363, \"min\": 994.0991401672363}}, \"EndTime\": 1517703791.224824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703790.218263}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:11 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:11 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_29ba4156-6b71-4ed9-9ad8-02c7c8ea7f31-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 56.49900436401367, \"sum\": 56.49900436401367, \"min\": 56.49900436401367}}, \"EndTime\": 1517703791.281509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703791.224875}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:11 INFO 140150847625024] Epoch[143] Batch[0] avg_epoch_loss=5.152922\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:11 INFO 140150847625024] Epoch[143] Batch[5] avg_epoch_loss=5.159274\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:11 INFO 140150847625024] Epoch[143] Batch [5]#011Speed: 355.32 samples/sec#011loss=5.159274\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:12 INFO 140150847625024] Epoch[143] Batch[10] avg_epoch_loss=5.155962\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:12 INFO 140150847625024] Epoch[143] Batch [10]#011Speed: 281.59 samples/sec#011loss=5.151986\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:12 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1142.204999923706, \"sum\": 1142.204999923706, \"min\": 1142.204999923706}}, \"EndTime\": 1517703792.436199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703791.281567}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:12 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:12 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_1419bd3a-07fd-4ea2-a1c1-7f365e95a1e5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.006853103637695, \"sum\": 14.006853103637695, \"min\": 14.006853103637695}}, \"EndTime\": 1517703792.450487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703792.43627}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:12 INFO 140150847625024] Epoch[144] Batch[0] avg_epoch_loss=5.113558\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:13 INFO 140150847625024] Epoch[144] Batch[5] avg_epoch_loss=5.165671\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:13 INFO 140150847625024] Epoch[144] Batch [5]#011Speed: 286.38 samples/sec#011loss=5.165671\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:13 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1039.748191833496, \"sum\": 1039.748191833496, \"min\": 1039.748191833496}}, \"EndTime\": 1517703793.505346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703792.450537}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:13 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:13 INFO 140150847625024] Epoch[145] Batch[0] avg_epoch_loss=5.206713\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] Epoch[145] Batch[5] avg_epoch_loss=13.211491\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] Epoch[145] Batch [5]#011Speed: 297.49 samples/sec#011loss=13.211491\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] Epoch[145] Batch[10] avg_epoch_loss=9.523022\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] Epoch[145] Batch [10]#011Speed: 344.32 samples/sec#011loss=5.096859\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1049.6079921722412, \"sum\": 1049.6079921722412, \"min\": 1049.6079921722412}}, \"EndTime\": 1517703794.567397, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703793.505412}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:14 INFO 140150847625024] Epoch[146] Batch[0] avg_epoch_loss=5.276522\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:15 INFO 140150847625024] Epoch[146] Batch[5] avg_epoch_loss=5.174333\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:15 INFO 140150847625024] Epoch[146] Batch [5]#011Speed: 324.08 samples/sec#011loss=5.174333\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:15 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1061.7918968200684, \"sum\": 1061.7918968200684, \"min\": 1061.7918968200684}}, \"EndTime\": 1517703795.645266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703794.567466}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:15 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:15 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_144d704e-65f0-4dac-9c6c-512ed76fc376-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.10196495056152, \"sum\": 57.10196495056152, \"min\": 57.10196495056152}}, \"EndTime\": 1517703795.702547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703795.645317}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:15 INFO 140150847625024] Epoch[147] Batch[0] avg_epoch_loss=5.159376\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] Epoch[147] Batch[5] avg_epoch_loss=5.172136\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] Epoch[147] Batch [5]#011Speed: 364.42 samples/sec#011loss=5.172136\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] Epoch[147] Batch[10] avg_epoch_loss=5.143737\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] Epoch[147] Batch [10]#011Speed: 288.31 samples/sec#011loss=5.109657\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1104.3379306793213, \"sum\": 1104.3379306793213, \"min\": 1104.3379306793213}}, \"EndTime\": 1517703796.818979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703795.70259}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_3f39baba-fecc-4003-8130-24bd5c812768-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.671159744262695, \"sum\": 13.671159744262695, \"min\": 13.671159744262695}}, \"EndTime\": 1517703796.832857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703796.819041}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:16 INFO 140150847625024] Epoch[148] Batch[0] avg_epoch_loss=5.083071\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] Epoch[148] Batch[5] avg_epoch_loss=5.101618\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] Epoch[148] Batch [5]#011Speed: 285.12 samples/sec#011loss=5.101618\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] Epoch[148] Batch[10] avg_epoch_loss=5.096198\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] Epoch[148] Batch [10]#011Speed: 348.08 samples/sec#011loss=5.089694\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1065.251111984253, \"sum\": 1065.251111984253, \"min\": 1065.251111984253}}, \"EndTime\": 1517703797.910162, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703796.832905}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:17 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_fee094a0-809f-4fd3-a2e2-9ebd4208a1e6-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.619903564453125, \"sum\": 59.619903564453125, \"min\": 59.619903564453125}}, \"EndTime\": 1517703797.970023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703797.910224}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:18 INFO 140150847625024] Epoch[149] Batch[0] avg_epoch_loss=5.157100\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:18 INFO 140150847625024] Epoch[149] Batch[5] avg_epoch_loss=13.278862\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:18 INFO 140150847625024] Epoch[149] Batch [5]#011Speed: 323.43 samples/sec#011loss=13.278862\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:18 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 988.9688491821289, \"sum\": 988.9688491821289, \"min\": 988.9688491821289}}, \"EndTime\": 1517703798.970867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703797.970076}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:18 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:23:19 INFO 140150847625024] Epoch[150] Batch[0] avg_epoch_loss=5.164355\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:19 INFO 140150847625024] Epoch[150] Batch[5] avg_epoch_loss=5.105467\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:19 INFO 140150847625024] Epoch[150] Batch [5]#011Speed: 326.35 samples/sec#011loss=5.105467\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:19 INFO 140150847625024] processed a total of 288 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 993.6211109161377, \"sum\": 993.6211109161377, \"min\": 993.6211109161377}}, \"EndTime\": 1517703799.979558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703798.97093}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:19 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:20 INFO 140150847625024] Epoch[151] Batch[0] avg_epoch_loss=5.149853\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:20 INFO 140150847625024] Epoch[151] Batch[5] avg_epoch_loss=5.124268\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:20 INFO 140150847625024] Epoch[151] Batch [5]#011Speed: 277.97 samples/sec#011loss=5.124268\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:20 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1008.030891418457, \"sum\": 1008.030891418457, \"min\": 1008.030891418457}}, \"EndTime\": 1517703800.999739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703799.979608}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:20 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:21 INFO 140150847625024] Epoch[152] Batch[0] avg_epoch_loss=5.146939\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:21 INFO 140150847625024] Epoch[152] Batch[5] avg_epoch_loss=5.175944\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:21 INFO 140150847625024] Epoch[152] Batch [5]#011Speed: 270.88 samples/sec#011loss=5.175944\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] Epoch[152] Batch[10] avg_epoch_loss=9.450513\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] Epoch[152] Batch [10]#011Speed: 363.10 samples/sec#011loss=14.579995\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1081.84814453125, \"sum\": 1081.84814453125, \"min\": 1081.84814453125}}, \"EndTime\": 1517703802.09378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703800.999803}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] Epoch[153] Batch[0] avg_epoch_loss=52.532299\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] Epoch[153] Batch[5] avg_epoch_loss=13.004108\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:22 INFO 140150847625024] Epoch[153] Batch [5]#011Speed: 338.94 samples/sec#011loss=13.004108\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:23 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 988.0521297454834, \"sum\": 988.0521297454834, \"min\": 988.0521297454834}}, \"EndTime\": 1517703803.098014, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703802.093846}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:23 INFO 140150847625024] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:23 INFO 140150847625024] Epoch[154] Batch[0] avg_epoch_loss=5.037742\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:23 INFO 140150847625024] Epoch[154] Batch[5] avg_epoch_loss=21.273350\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:23 INFO 140150847625024] Epoch[154] Batch [5]#011Speed: 354.22 samples/sec#011loss=21.273350\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:24 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 982.0630550384521, \"sum\": 982.0630550384521, \"min\": 982.0630550384521}}, \"EndTime\": 1517703804.092995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703803.098081}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:24 INFO 140150847625024] loss did not improve for 6 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:24 INFO 140150847625024] Epoch[155] Batch[0] avg_epoch_loss=5.158256\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:24 INFO 140150847625024] Epoch[155] Batch[5] avg_epoch_loss=5.101290\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:24 INFO 140150847625024] Epoch[155] Batch [5]#011Speed: 366.88 samples/sec#011loss=5.101290\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] Epoch[155] Batch[10] avg_epoch_loss=5.080112\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] Epoch[155] Batch [10]#011Speed: 296.33 samples/sec#011loss=5.054697\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1160.599946975708, \"sum\": 1160.599946975708, \"min\": 1160.599946975708}}, \"EndTime\": 1517703805.269286, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703804.093067}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5e4de955-aa76-4c28-8b3c-5fd703749a77-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.135934829711914, \"sum\": 62.135934829711914, \"min\": 62.135934829711914}}, \"EndTime\": 1517703805.331672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703805.269366}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] Epoch[156] Batch[0] avg_epoch_loss=5.062740\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] Epoch[156] Batch[5] avg_epoch_loss=5.060845\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:25 INFO 140150847625024] Epoch[156] Batch [5]#011Speed: 341.24 samples/sec#011loss=5.060845\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:26 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1027.7960300445557, \"sum\": 1027.7960300445557, \"min\": 1027.7960300445557}}, \"EndTime\": 1517703806.371691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703805.331728}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:26 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:26 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ca213488-be95-496f-a26a-1088070c679c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 55.93299865722656, \"sum\": 55.93299865722656, \"min\": 55.93299865722656}}, \"EndTime\": 1517703806.427847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703806.371755}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:26 INFO 140150847625024] Epoch[157] Batch[0] avg_epoch_loss=5.165334\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] Epoch[157] Batch[5] avg_epoch_loss=5.071221\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] Epoch[157] Batch [5]#011Speed: 347.87 samples/sec#011loss=5.071221\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] Epoch[157] Batch[10] avg_epoch_loss=5.051438\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] Epoch[157] Batch [10]#011Speed: 271.81 samples/sec#011loss=5.027698\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.9610271453857, \"sum\": 1165.9610271453857, \"min\": 1165.9610271453857}}, \"EndTime\": 1517703807.60643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703806.427901}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_10491874-978d-4dc5-881c-bdeb0f781b5c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.641119003295898, \"sum\": 13.641119003295898, \"min\": 13.641119003295898}}, \"EndTime\": 1517703807.620284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703807.606493}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:27 INFO 140150847625024] Epoch[158] Batch[0] avg_epoch_loss=5.008200\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] Epoch[158] Batch[5] avg_epoch_loss=4.993628\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] Epoch[158] Batch [5]#011Speed: 253.22 samples/sec#011loss=4.993628\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] Epoch[158] Batch[10] avg_epoch_loss=5.000862\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] Epoch[158] Batch [10]#011Speed: 361.40 samples/sec#011loss=5.009543\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1137.1641159057617, \"sum\": 1137.1641159057617, \"min\": 1137.1641159057617}}, \"EndTime\": 1517703808.76967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703807.620394}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_41edd4ec-236c-4060-ac62-7025b10b0463-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 54.116010665893555, \"sum\": 54.116010665893555, \"min\": 54.116010665893555}}, \"EndTime\": 1517703808.823989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703808.769723}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:28 INFO 140150847625024] Epoch[159] Batch[0] avg_epoch_loss=5.204042\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:23:29 INFO 140150847625024] Epoch[159] Batch[5] avg_epoch_loss=12.853385\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:29 INFO 140150847625024] Epoch[159] Batch [5]#011Speed: 332.07 samples/sec#011loss=12.853385\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:29 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 951.246976852417, \"sum\": 951.246976852417, \"min\": 951.246976852417}}, \"EndTime\": 1517703809.787551, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703808.824036}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:29 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:29 INFO 140150847625024] Epoch[160] Batch[0] avg_epoch_loss=5.143195\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:30 INFO 140150847625024] Epoch[160] Batch[5] avg_epoch_loss=5.035442\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:30 INFO 140150847625024] Epoch[160] Batch [5]#011Speed: 324.12 samples/sec#011loss=5.035442\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:30 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1050.7230758666992, \"sum\": 1050.7230758666992, \"min\": 1050.7230758666992}}, \"EndTime\": 1517703810.851533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703809.7876}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:30 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:31 INFO 140150847625024] Epoch[161] Batch[0] avg_epoch_loss=5.095079\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:31 INFO 140150847625024] Epoch[161] Batch[5] avg_epoch_loss=5.067312\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:31 INFO 140150847625024] Epoch[161] Batch [5]#011Speed: 331.95 samples/sec#011loss=5.067312\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:31 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1037.4131202697754, \"sum\": 1037.4131202697754, \"min\": 1037.4131202697754}}, \"EndTime\": 1517703811.901908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703810.851608}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:31 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:32 INFO 140150847625024] Epoch[162] Batch[0] avg_epoch_loss=4.993683\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:32 INFO 140150847625024] Epoch[162] Batch[5] avg_epoch_loss=5.004939\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:32 INFO 140150847625024] Epoch[162] Batch [5]#011Speed: 351.28 samples/sec#011loss=5.004939\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] Epoch[162] Batch[10] avg_epoch_loss=5.016519\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] Epoch[162] Batch [10]#011Speed: 274.76 samples/sec#011loss=5.030415\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1184.9629878997803, \"sum\": 1184.9629878997803, \"min\": 1184.9629878997803}}, \"EndTime\": 1517703813.099529, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703811.901991}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] Epoch[163] Batch[0] avg_epoch_loss=5.040148\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] Epoch[163] Batch[5] avg_epoch_loss=5.024167\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:33 INFO 140150847625024] Epoch[163] Batch [5]#011Speed: 288.27 samples/sec#011loss=5.024167\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] Epoch[163] Batch[10] avg_epoch_loss=4.985568\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] Epoch[163] Batch [10]#011Speed: 348.68 samples/sec#011loss=4.939248\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1058.6440563201904, \"sum\": 1058.6440563201904, \"min\": 1058.6440563201904}}, \"EndTime\": 1517703814.170098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703813.099581}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_f23f1654-2695-4ebe-a884-d209007e0cee-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.5709342956543, \"sum\": 57.5709342956543, \"min\": 57.5709342956543}}, \"EndTime\": 1517703814.227897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703814.170163}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] Epoch[164] Batch[0] avg_epoch_loss=5.044174\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] Epoch[164] Batch[5] avg_epoch_loss=5.001575\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:34 INFO 140150847625024] Epoch[164] Batch [5]#011Speed: 328.44 samples/sec#011loss=5.001575\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:35 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1012.9029750823975, \"sum\": 1012.9029750823975, \"min\": 1012.9029750823975}}, \"EndTime\": 1517703815.252434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703814.22796}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:35 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:35 INFO 140150847625024] Epoch[165] Batch[0] avg_epoch_loss=5.199829\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:35 INFO 140150847625024] Epoch[165] Batch[5] avg_epoch_loss=5.029308\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:35 INFO 140150847625024] Epoch[165] Batch [5]#011Speed: 346.28 samples/sec#011loss=5.029308\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:36 INFO 140150847625024] Epoch[165] Batch[10] avg_epoch_loss=5.017373\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:36 INFO 140150847625024] Epoch[165] Batch [10]#011Speed: 274.16 samples/sec#011loss=5.003051\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:36 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1176.145076751709, \"sum\": 1176.145076751709, \"min\": 1176.145076751709}}, \"EndTime\": 1517703816.449037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703815.252495}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:36 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:36 INFO 140150847625024] Epoch[166] Batch[0] avg_epoch_loss=4.991146\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:37 INFO 140150847625024] Epoch[166] Batch[5] avg_epoch_loss=5.006201\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:37 INFO 140150847625024] Epoch[166] Batch [5]#011Speed: 277.37 samples/sec#011loss=5.006201\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:37 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1075.6349563598633, \"sum\": 1075.6349563598633, \"min\": 1075.6349563598633}}, \"EndTime\": 1517703817.539008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703816.44911}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:37 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:37 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_13b52693-ad05-44d8-b9e6-0b24b4c2bb83-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.03498649597168, \"sum\": 14.03498649597168, \"min\": 14.03498649597168}}, \"EndTime\": 1517703817.553285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703817.539085}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:37 INFO 140150847625024] Epoch[167] Batch[0] avg_epoch_loss=4.957959\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] Epoch[167] Batch[5] avg_epoch_loss=4.995650\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] Epoch[167] Batch [5]#011Speed: 266.85 samples/sec#011loss=4.995650\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] Epoch[167] Batch[10] avg_epoch_loss=4.989083\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] Epoch[167] Batch [10]#011Speed: 371.67 samples/sec#011loss=4.981203\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1080.1420211791992, \"sum\": 1080.1420211791992, \"min\": 1080.1420211791992}}, \"EndTime\": 1517703818.647575, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703817.553329}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:38 INFO 140150847625024] Epoch[168] Batch[0] avg_epoch_loss=5.012837\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:23:39 INFO 140150847625024] Epoch[168] Batch[5] avg_epoch_loss=4.976345\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:39 INFO 140150847625024] Epoch[168] Batch [5]#011Speed: 352.36 samples/sec#011loss=4.976345\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:39 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1026.8220901489258, \"sum\": 1026.8220901489258, \"min\": 1026.8220901489258}}, \"EndTime\": 1517703819.689709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703818.64765}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:39 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:39 INFO 140150847625024] Epoch[169] Batch[0] avg_epoch_loss=5.027636\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] Epoch[169] Batch[5] avg_epoch_loss=4.957502\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] Epoch[169] Batch [5]#011Speed: 334.48 samples/sec#011loss=4.957502\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] Epoch[169] Batch[10] avg_epoch_loss=4.951811\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] Epoch[169] Batch [10]#011Speed: 293.54 samples/sec#011loss=4.944982\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1168.6949729919434, \"sum\": 1168.6949729919434, \"min\": 1168.6949729919434}}, \"EndTime\": 1517703820.871094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703819.689777}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ba6da50c-d788-4ebb-8259-eaba56a46602-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.981176376342773, \"sum\": 12.981176376342773, \"min\": 12.981176376342773}}, \"EndTime\": 1517703820.884238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703820.871141}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:40 INFO 140150847625024] Epoch[170] Batch[0] avg_epoch_loss=5.033997\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:41 INFO 140150847625024] Epoch[170] Batch[5] avg_epoch_loss=4.943653\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:41 INFO 140150847625024] Epoch[170] Batch [5]#011Speed: 286.81 samples/sec#011loss=4.943653\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:41 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1014.3780708312988, \"sum\": 1014.3780708312988, \"min\": 1014.3780708312988}}, \"EndTime\": 1517703821.910684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703820.884274}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:41 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:41 INFO 140150847625024] Epoch[171] Batch[0] avg_epoch_loss=4.896946\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:42 INFO 140150847625024] Epoch[171] Batch[5] avg_epoch_loss=20.585442\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:42 INFO 140150847625024] Epoch[171] Batch [5]#011Speed: 299.04 samples/sec#011loss=20.585442\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:42 INFO 140150847625024] Epoch[171] Batch[10] avg_epoch_loss=13.469928\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:42 INFO 140150847625024] Epoch[171] Batch [10]#011Speed: 357.18 samples/sec#011loss=4.931312\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:42 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1021.1961269378662, \"sum\": 1021.1961269378662, \"min\": 1021.1961269378662}}, \"EndTime\": 1517703822.943591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703821.910736}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:42 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:43 INFO 140150847625024] Epoch[172] Batch[0] avg_epoch_loss=4.977200\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:43 INFO 140150847625024] Epoch[172] Batch[5] avg_epoch_loss=4.936842\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:43 INFO 140150847625024] Epoch[172] Batch [5]#011Speed: 331.08 samples/sec#011loss=4.936842\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:43 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1021.697998046875, \"sum\": 1021.697998046875, \"min\": 1021.697998046875}}, \"EndTime\": 1517703823.981639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703822.943654}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:43 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:44 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_9088c9af-30cc-44c2-a0af-7ed6d7c76c83-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 53.436994552612305, \"sum\": 53.436994552612305, \"min\": 53.436994552612305}}, \"EndTime\": 1517703824.035287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703823.981703}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:44 INFO 140150847625024] Epoch[173] Batch[0] avg_epoch_loss=5.133544\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:44 INFO 140150847625024] Epoch[173] Batch[5] avg_epoch_loss=4.966259\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:44 INFO 140150847625024] Epoch[173] Batch [5]#011Speed: 341.26 samples/sec#011loss=4.966259\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:45 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1007.7989101409912, \"sum\": 1007.7989101409912, \"min\": 1007.7989101409912}}, \"EndTime\": 1517703825.058993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703824.035342}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:45 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:45 INFO 140150847625024] Epoch[174] Batch[0] avg_epoch_loss=4.972862\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:45 INFO 140150847625024] Epoch[174] Batch[5] avg_epoch_loss=4.924062\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:45 INFO 140150847625024] Epoch[174] Batch [5]#011Speed: 360.36 samples/sec#011loss=4.924062\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] Epoch[174] Batch[10] avg_epoch_loss=4.919568\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] Epoch[174] Batch [10]#011Speed: 300.55 samples/sec#011loss=4.914176\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1123.5129833221436, \"sum\": 1123.5129833221436, \"min\": 1123.5129833221436}}, \"EndTime\": 1517703826.199494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703825.059064}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_97c6f65f-a978-4722-9d26-244c943c0bc6-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.005971908569336, \"sum\": 13.005971908569336, \"min\": 13.005971908569336}}, \"EndTime\": 1517703826.212691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703826.19955}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] Epoch[175] Batch[0] avg_epoch_loss=4.860426\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] Epoch[175] Batch[5] avg_epoch_loss=4.904921\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:46 INFO 140150847625024] Epoch[175] Batch [5]#011Speed: 309.25 samples/sec#011loss=4.904921\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:47 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1010.2789402008057, \"sum\": 1010.2789402008057, \"min\": 1010.2789402008057}}, \"EndTime\": 1517703827.23484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703826.212726}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:47 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:47 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_be49fa52-e2ca-45ba-bdea-5a8e7ef58f4e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.797998428344727, \"sum\": 13.797998428344727, \"min\": 13.797998428344727}}, \"EndTime\": 1517703827.248856, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703827.234906}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:47 INFO 140150847625024] Epoch[176] Batch[0] avg_epoch_loss=4.872674\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:47 INFO 140150847625024] Epoch[176] Batch[5] avg_epoch_loss=4.913963\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:47 INFO 140150847625024] Epoch[176] Batch [5]#011Speed: 269.34 samples/sec#011loss=4.913963\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:48 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1033.6060523986816, \"sum\": 1033.6060523986816, \"min\": 1033.6060523986816}}, \"EndTime\": 1517703828.294131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703827.248901}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:48 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:48 INFO 140150847625024] Epoch[177] Batch[0] avg_epoch_loss=4.980214\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:48 INFO 140150847625024] Epoch[177] Batch[5] avg_epoch_loss=4.900628\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:48 INFO 140150847625024] Epoch[177] Batch [5]#011Speed: 285.93 samples/sec#011loss=4.900628\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:23:49 INFO 140150847625024] Epoch[177] Batch[10] avg_epoch_loss=4.873586\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:49 INFO 140150847625024] Epoch[177] Batch [10]#011Speed: 351.48 samples/sec#011loss=4.841134\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:49 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1065.526008605957, \"sum\": 1065.526008605957, \"min\": 1065.526008605957}}, \"EndTime\": 1517703829.37219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703828.294197}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:49 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:49 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_a8216327-8353-47c8-9ddc-d61e0eea64df-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.11503791809082, \"sum\": 74.11503791809082, \"min\": 74.11503791809082}}, \"EndTime\": 1517703829.446571, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703829.372254}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:49 INFO 140150847625024] Epoch[178] Batch[0] avg_epoch_loss=4.829898\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] Epoch[178] Batch[5] avg_epoch_loss=12.444548\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] Epoch[178] Batch [5]#011Speed: 337.26 samples/sec#011loss=12.444548\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] Epoch[178] Batch[10] avg_epoch_loss=9.017305\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] Epoch[178] Batch [10]#011Speed: 273.89 samples/sec#011loss=4.904613\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1157.9389572143555, \"sum\": 1157.9389572143555, \"min\": 1157.9389572143555}}, \"EndTime\": 1517703830.616799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703829.44663}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:50 INFO 140150847625024] Epoch[179] Batch[0] avg_epoch_loss=4.877260\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:51 INFO 140150847625024] Epoch[179] Batch[5] avg_epoch_loss=4.883017\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:51 INFO 140150847625024] Epoch[179] Batch [5]#011Speed: 283.00 samples/sec#011loss=4.883017\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:51 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1005.5339336395264, \"sum\": 1005.5339336395264, \"min\": 1005.5339336395264}}, \"EndTime\": 1517703831.635197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703830.616847}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:51 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:51 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_7376651c-a7b8-4055-acb8-1a57b037814f-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.132095336914062, \"sum\": 13.132095336914062, \"min\": 13.132095336914062}}, \"EndTime\": 1517703831.648538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703831.63526}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:51 INFO 140150847625024] Epoch[180] Batch[0] avg_epoch_loss=4.919106\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:52 INFO 140150847625024] Epoch[180] Batch[5] avg_epoch_loss=4.907581\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:52 INFO 140150847625024] Epoch[180] Batch [5]#011Speed: 285.29 samples/sec#011loss=4.907581\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:52 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1038.9630794525146, \"sum\": 1038.9630794525146, \"min\": 1038.9630794525146}}, \"EndTime\": 1517703832.699682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703831.648583}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:52 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:52 INFO 140150847625024] Epoch[181] Batch[0] avg_epoch_loss=4.850295\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] Epoch[181] Batch[5] avg_epoch_loss=4.869914\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] Epoch[181] Batch [5]#011Speed: 280.07 samples/sec#011loss=4.869914\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] Epoch[181] Batch[10] avg_epoch_loss=4.858638\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] Epoch[181] Batch [10]#011Speed: 365.17 samples/sec#011loss=4.845108\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1059.6420764923096, \"sum\": 1059.6420764923096, \"min\": 1059.6420764923096}}, \"EndTime\": 1517703833.771428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703832.699746}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_f6e022dc-1ea3-43eb-8a04-3565424aa2ff-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.19799613952637, \"sum\": 61.19799613952637, \"min\": 61.19799613952637}}, \"EndTime\": 1517703833.832883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703833.771493}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:53 INFO 140150847625024] Epoch[182] Batch[0] avg_epoch_loss=4.871414\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:54 INFO 140150847625024] Epoch[182] Batch[5] avg_epoch_loss=4.839485\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:54 INFO 140150847625024] Epoch[182] Batch [5]#011Speed: 324.52 samples/sec#011loss=4.839485\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:54 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1033.8811874389648, \"sum\": 1033.8811874389648, \"min\": 1033.8811874389648}}, \"EndTime\": 1517703834.878989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703833.832935}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:54 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:54 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_104c772a-ef33-4daf-a0b7-cfe473192627-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.75996971130371, \"sum\": 64.75996971130371, \"min\": 64.75996971130371}}, \"EndTime\": 1517703834.943932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703834.879039}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:55 INFO 140150847625024] Epoch[183] Batch[0] avg_epoch_loss=4.959803\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:55 INFO 140150847625024] Epoch[183] Batch[5] avg_epoch_loss=4.877759\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:55 INFO 140150847625024] Epoch[183] Batch [5]#011Speed: 356.76 samples/sec#011loss=4.877759\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:55 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 947.1659660339355, \"sum\": 947.1659660339355, \"min\": 947.1659660339355}}, \"EndTime\": 1517703835.903214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703834.943977}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:55 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:56 INFO 140150847625024] Epoch[184] Batch[0] avg_epoch_loss=4.948845\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:56 INFO 140150847625024] Epoch[184] Batch[5] avg_epoch_loss=4.848732\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:56 INFO 140150847625024] Epoch[184] Batch [5]#011Speed: 329.35 samples/sec#011loss=4.848732\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] Epoch[184] Batch[10] avg_epoch_loss=4.856911\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] Epoch[184] Batch [10]#011Speed: 275.74 samples/sec#011loss=4.866725\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1211.9519710540771, \"sum\": 1211.9519710540771, \"min\": 1211.9519710540771}}, \"EndTime\": 1517703837.128072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703835.903263}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] Epoch[185] Batch[0] avg_epoch_loss=4.933856\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] Epoch[185] Batch[5] avg_epoch_loss=4.839555\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:57 INFO 140150847625024] Epoch[185] Batch [5]#011Speed: 283.87 samples/sec#011loss=4.839555\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:58 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1053.278923034668, \"sum\": 1053.278923034668, \"min\": 1053.278923034668}}, \"EndTime\": 1517703838.195918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703837.128138}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:58 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:58 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_0451d392-99c3-4f5d-a28a-13db4af7e9a3-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.331890106201172, \"sum\": 13.331890106201172, \"min\": 13.331890106201172}}, \"EndTime\": 1517703838.209512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703838.195991}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:58 INFO 140150847625024] Epoch[186] Batch[0] avg_epoch_loss=4.852726\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:58 INFO 140150847625024] Epoch[186] Batch[5] avg_epoch_loss=4.864547\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:58 INFO 140150847625024] Epoch[186] Batch [5]#011Speed: 252.88 samples/sec#011loss=4.864547\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] Epoch[186] Batch[10] avg_epoch_loss=4.861346\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] Epoch[186] Batch [10]#011Speed: 337.81 samples/sec#011loss=4.857504\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1140.3429508209229, \"sum\": 1140.3429508209229, \"min\": 1140.3429508209229}}, \"EndTime\": 1517703839.365636, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703838.209553}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] Epoch[187] Batch[0] avg_epoch_loss=4.756268\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] Epoch[187] Batch[5] avg_epoch_loss=4.771707\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:23:59 INFO 140150847625024] Epoch[187] Batch [5]#011Speed: 347.23 samples/sec#011loss=4.771707\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:00 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1019.7451114654541, \"sum\": 1019.7451114654541, \"min\": 1019.7451114654541}}, \"EndTime\": 1517703840.401365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703839.365697}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:00 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:00 INFO 140150847625024] Epoch[188] Batch[0] avg_epoch_loss=4.800493\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:01 INFO 140150847625024] Epoch[188] Batch[5] avg_epoch_loss=20.110815\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:01 INFO 140150847625024] Epoch[188] Batch [5]#011Speed: 331.06 samples/sec#011loss=20.110815\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:01 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1063.9569759368896, \"sum\": 1063.9569759368896, \"min\": 1063.9569759368896}}, \"EndTime\": 1517703841.479819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703840.401453}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:01 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:01 INFO 140150847625024] Epoch[189] Batch[0] avg_epoch_loss=4.940163\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] Epoch[189] Batch[5] avg_epoch_loss=4.828867\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] Epoch[189] Batch [5]#011Speed: 313.77 samples/sec#011loss=4.828867\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] Epoch[189] Batch[10] avg_epoch_loss=4.796068\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] Epoch[189] Batch [10]#011Speed: 273.55 samples/sec#011loss=4.756709\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1274.7628688812256, \"sum\": 1274.7628688812256, \"min\": 1274.7628688812256}}, \"EndTime\": 1517703842.766681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703841.47988}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_b83a039c-0f46-45cc-9809-4e0284230912-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 53.929805755615234, \"sum\": 53.929805755615234, \"min\": 53.929805755615234}}, \"EndTime\": 1517703842.820846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703842.766753}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:02 INFO 140150847625024] Epoch[190] Batch[0] avg_epoch_loss=4.860298\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:03 INFO 140150847625024] Epoch[190] Batch[5] avg_epoch_loss=4.799575\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:03 INFO 140150847625024] Epoch[190] Batch [5]#011Speed: 333.88 samples/sec#011loss=4.799575\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:03 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1003.654956817627, \"sum\": 1003.654956817627, \"min\": 1003.654956817627}}, \"EndTime\": 1517703843.836488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703842.820905}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:03 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:03 INFO 140150847625024] Epoch[191] Batch[0] avg_epoch_loss=4.754947\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:04 INFO 140150847625024] Epoch[191] Batch[5] avg_epoch_loss=4.826282\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:04 INFO 140150847625024] Epoch[191] Batch [5]#011Speed: 360.31 samples/sec#011loss=4.826282\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:04 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 951.3800144195557, \"sum\": 951.3800144195557, \"min\": 951.3800144195557}}, \"EndTime\": 1517703844.80035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703843.83654}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:04 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:04 INFO 140150847625024] Epoch[192] Batch[0] avg_epoch_loss=4.902342\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:05 INFO 140150847625024] Epoch[192] Batch[5] avg_epoch_loss=4.780817\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:05 INFO 140150847625024] Epoch[192] Batch [5]#011Speed: 333.66 samples/sec#011loss=4.780817\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] Epoch[192] Batch[10] avg_epoch_loss=4.763953\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] Epoch[192] Batch [10]#011Speed: 278.91 samples/sec#011loss=4.743717\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1191.4899349212646, \"sum\": 1191.4899349212646, \"min\": 1191.4899349212646}}, \"EndTime\": 1517703846.008928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703844.800419}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_29dc27a5-ccbd-4f90-8cc8-d1cc9f192962-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.895988464355469, \"sum\": 13.895988464355469, \"min\": 13.895988464355469}}, \"EndTime\": 1517703846.023036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703846.008991}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] Epoch[193] Batch[0] avg_epoch_loss=4.752172\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] Epoch[193] Batch[5] avg_epoch_loss=4.769880\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:06 INFO 140150847625024] Epoch[193] Batch [5]#011Speed: 290.31 samples/sec#011loss=4.769880\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:07 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1033.236026763916, \"sum\": 1033.236026763916, \"min\": 1033.236026763916}}, \"EndTime\": 1517703847.06875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703846.023085}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:07 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:07 INFO 140150847625024] Epoch[194] Batch[0] avg_epoch_loss=4.793701\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:07 INFO 140150847625024] Epoch[194] Batch[5] avg_epoch_loss=4.798333\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:07 INFO 140150847625024] Epoch[194] Batch [5]#011Speed: 252.63 samples/sec#011loss=4.798333\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] Epoch[194] Batch[10] avg_epoch_loss=4.775201\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] Epoch[194] Batch [10]#011Speed: 349.73 samples/sec#011loss=4.747442\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1126.6210079193115, \"sum\": 1126.6210079193115, \"min\": 1126.6210079193115}}, \"EndTime\": 1517703848.207996, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703847.068814}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] Epoch[195] Batch[0] avg_epoch_loss=4.987851\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] Epoch[195] Batch[5] avg_epoch_loss=19.540220\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:08 INFO 140150847625024] Epoch[195] Batch [5]#011Speed: 335.50 samples/sec#011loss=19.540220\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:24:09 INFO 140150847625024] processed a total of 288 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1005.5019855499268, \"sum\": 1005.5019855499268, \"min\": 1005.5019855499268}}, \"EndTime\": 1517703849.22681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703848.20805}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:09 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:09 INFO 140150847625024] Epoch[196] Batch[0] avg_epoch_loss=4.748453\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:09 INFO 140150847625024] Epoch[196] Batch[5] avg_epoch_loss=4.795711\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:09 INFO 140150847625024] Epoch[196] Batch [5]#011Speed: 272.49 samples/sec#011loss=4.795711\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] Epoch[196] Batch[10] avg_epoch_loss=4.777947\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] Epoch[196] Batch [10]#011Speed: 342.94 samples/sec#011loss=4.756631\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1094.5498943328857, \"sum\": 1094.5498943328857, \"min\": 1094.5498943328857}}, \"EndTime\": 1517703850.333718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703849.226863}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] Epoch[197] Batch[0] avg_epoch_loss=4.741167\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] Epoch[197] Batch[5] avg_epoch_loss=4.787128\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:10 INFO 140150847625024] Epoch[197] Batch [5]#011Speed: 330.92 samples/sec#011loss=4.787128\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:11 INFO 140150847625024] Epoch[197] Batch[10] avg_epoch_loss=4.763222\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:11 INFO 140150847625024] Epoch[197] Batch [10]#011Speed: 264.25 samples/sec#011loss=4.734535\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:11 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1252.737045288086, \"sum\": 1252.737045288086, \"min\": 1252.737045288086}}, \"EndTime\": 1517703851.603465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703850.333782}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:11 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:11 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_1fb2e21c-c117-4f14-b34c-cdd6bb9947aa-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 52.80494689941406, \"sum\": 52.80494689941406, \"min\": 52.80494689941406}}, \"EndTime\": 1517703851.656463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703851.603522}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:11 INFO 140150847625024] Epoch[198] Batch[0] avg_epoch_loss=4.759180\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] Epoch[198] Batch[5] avg_epoch_loss=4.730297\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] Epoch[198] Batch [5]#011Speed: 351.36 samples/sec#011loss=4.730297\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] Epoch[198] Batch[10] avg_epoch_loss=4.737885\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] Epoch[198] Batch [10]#011Speed: 293.10 samples/sec#011loss=4.746991\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1117.9189682006836, \"sum\": 1117.9189682006836, \"min\": 1117.9189682006836}}, \"EndTime\": 1517703852.787055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703851.65651}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_9f200ad6-b1ef-4101-bc3c-b2feba9f33a7-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.93890380859375, \"sum\": 13.93890380859375, \"min\": 13.93890380859375}}, \"EndTime\": 1517703852.8012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703852.787117}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:12 INFO 140150847625024] Epoch[199] Batch[0] avg_epoch_loss=4.955691\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] Epoch[199] Batch[5] avg_epoch_loss=4.747527\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] Epoch[199] Batch [5]#011Speed: 280.07 samples/sec#011loss=4.747527\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] Epoch[199] Batch[10] avg_epoch_loss=4.702039\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] Epoch[199] Batch [10]#011Speed: 342.56 samples/sec#011loss=4.647453\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1082.4198722839355, \"sum\": 1082.4198722839355, \"min\": 1082.4198722839355}}, \"EndTime\": 1517703853.895717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703852.801248}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:13 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ad1fba11-476e-4b17-a889-c2a60e49be17-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.981916427612305, \"sum\": 61.981916427612305, \"min\": 61.981916427612305}}, \"EndTime\": 1517703853.95795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703853.895792}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:14 INFO 140150847625024] Epoch[200] Batch[0] avg_epoch_loss=4.787706\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:14 INFO 140150847625024] Epoch[200] Batch[5] avg_epoch_loss=4.756791\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:14 INFO 140150847625024] Epoch[200] Batch [5]#011Speed: 351.28 samples/sec#011loss=4.756791\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:14 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 949.0659236907959, \"sum\": 949.0659236907959, \"min\": 949.0659236907959}}, \"EndTime\": 1517703854.921218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703853.95802}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:14 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:15 INFO 140150847625024] Epoch[201] Batch[0] avg_epoch_loss=4.853640\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:15 INFO 140150847625024] Epoch[201] Batch[5] avg_epoch_loss=19.263801\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:15 INFO 140150847625024] Epoch[201] Batch [5]#011Speed: 354.43 samples/sec#011loss=19.263801\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] Epoch[201] Batch[10] avg_epoch_loss=12.632898\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] Epoch[201] Batch [10]#011Speed: 290.29 samples/sec#011loss=4.675814\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1126.1188983917236, \"sum\": 1126.1188983917236, \"min\": 1126.1188983917236}}, \"EndTime\": 1517703856.062581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703854.921282}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] Epoch[202] Batch[0] avg_epoch_loss=4.714533\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] Epoch[202] Batch[5] avg_epoch_loss=4.695658\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:16 INFO 140150847625024] Epoch[202] Batch [5]#011Speed: 251.37 samples/sec#011loss=4.695658\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:17 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1137.9270553588867, \"sum\": 1137.9270553588867, \"min\": 1137.9270553588867}}, \"EndTime\": 1517703857.215471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703856.062656}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:17 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:17 INFO 140150847625024] Epoch[203] Batch[0] avg_epoch_loss=4.693319\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:17 INFO 140150847625024] Epoch[203] Batch[5] avg_epoch_loss=4.715346\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:17 INFO 140150847625024] Epoch[203] Batch [5]#011Speed: 296.10 samples/sec#011loss=4.715346\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:18 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1011.746883392334, \"sum\": 1011.746883392334, \"min\": 1011.746883392334}}, \"EndTime\": 1517703858.23972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703857.21552}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:18 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:18 INFO 140150847625024] Epoch[204] Batch[0] avg_epoch_loss=4.784135\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:18 INFO 140150847625024] Epoch[204] Batch[5] avg_epoch_loss=4.722607\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:18 INFO 140150847625024] Epoch[204] Batch [5]#011Speed: 290.38 samples/sec#011loss=4.722607\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:24:19 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1036.1008644104004, \"sum\": 1036.1008644104004, \"min\": 1036.1008644104004}}, \"EndTime\": 1517703859.290316, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703858.239784}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:19 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:19 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_dbefb370-633c-4732-b160-2c0d7ccfba79-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.371156692504883, \"sum\": 14.371156692504883, \"min\": 14.371156692504883}}, \"EndTime\": 1517703859.304923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703859.290389}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:19 INFO 140150847625024] Epoch[205] Batch[0] avg_epoch_loss=4.716486\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:19 INFO 140150847625024] Epoch[205] Batch[5] avg_epoch_loss=4.707671\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:19 INFO 140150847625024] Epoch[205] Batch [5]#011Speed: 261.80 samples/sec#011loss=4.707671\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:20 INFO 140150847625024] Epoch[205] Batch[10] avg_epoch_loss=12.506888\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:20 INFO 140150847625024] Epoch[205] Batch [10]#011Speed: 355.70 samples/sec#011loss=21.865949\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:20 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1106.7500114440918, \"sum\": 1106.7500114440918, \"min\": 1106.7500114440918}}, \"EndTime\": 1517703860.426946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703859.304973}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:20 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:20 INFO 140150847625024] Epoch[206] Batch[0] avg_epoch_loss=4.712861\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:21 INFO 140150847625024] Epoch[206] Batch[5] avg_epoch_loss=4.703950\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:21 INFO 140150847625024] Epoch[206] Batch [5]#011Speed: 356.78 samples/sec#011loss=4.703950\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:21 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1016.1559581756592, \"sum\": 1016.1559581756592, \"min\": 1016.1559581756592}}, \"EndTime\": 1517703861.459405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703860.427012}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:21 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:21 INFO 140150847625024] Epoch[207] Batch[0] avg_epoch_loss=4.726291\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] Epoch[207] Batch[5] avg_epoch_loss=4.675621\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] Epoch[207] Batch [5]#011Speed: 365.99 samples/sec#011loss=4.675621\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] Epoch[207] Batch[10] avg_epoch_loss=4.686122\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] Epoch[207] Batch [10]#011Speed: 298.04 samples/sec#011loss=4.698724\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1101.0761260986328, \"sum\": 1101.0761260986328, \"min\": 1101.0761260986328}}, \"EndTime\": 1517703862.575498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703861.459473}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_832d3ea9-a942-4352-9e01-17af54590663-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.158010482788086, \"sum\": 14.158010482788086, \"min\": 14.158010482788086}}, \"EndTime\": 1517703862.589884, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703862.575569}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:22 INFO 140150847625024] Epoch[208] Batch[0] avg_epoch_loss=4.778098\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:23 INFO 140150847625024] Epoch[208] Batch[5] avg_epoch_loss=4.676298\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:23 INFO 140150847625024] Epoch[208] Batch [5]#011Speed: 266.81 samples/sec#011loss=4.676298\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:23 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1047.0869541168213, \"sum\": 1047.0869541168213, \"min\": 1047.0869541168213}}, \"EndTime\": 1517703863.651267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703862.58993}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:23 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:23 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_03cacb5a-32bb-42fa-b09e-68b993ce58b9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.799905776977539, \"sum\": 13.799905776977539, \"min\": 13.799905776977539}}, \"EndTime\": 1517703863.665257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703863.651318}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:23 INFO 140150847625024] Epoch[209] Batch[0] avg_epoch_loss=4.775720\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] Epoch[209] Batch[5] avg_epoch_loss=4.700300\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] Epoch[209] Batch [5]#011Speed: 284.49 samples/sec#011loss=4.700300\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] Epoch[209] Batch[10] avg_epoch_loss=4.667198\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] Epoch[209] Batch [10]#011Speed: 405.59 samples/sec#011loss=4.627476\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1011.2137794494629, \"sum\": 1011.2137794494629, \"min\": 1011.2137794494629}}, \"EndTime\": 1517703864.688596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703863.665304}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_51328ab0-d86c-45f9-bf82-1de5967ef61a-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 56.054115295410156, \"sum\": 56.054115295410156, \"min\": 56.054115295410156}}, \"EndTime\": 1517703864.74491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703864.688663}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:24 INFO 140150847625024] Epoch[210] Batch[0] avg_epoch_loss=4.690147\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] Epoch[210] Batch[5] avg_epoch_loss=4.661128\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] Epoch[210] Batch [5]#011Speed: 335.10 samples/sec#011loss=4.661128\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] Epoch[210] Batch[10] avg_epoch_loss=12.313002\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] Epoch[210] Batch [10]#011Speed: 288.52 samples/sec#011loss=21.495251\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1140.8820152282715, \"sum\": 1140.8820152282715, \"min\": 1140.8820152282715}}, \"EndTime\": 1517703865.898199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703864.74496}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:25 INFO 140150847625024] Epoch[211] Batch[0] avg_epoch_loss=4.714360\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:26 INFO 140150847625024] Epoch[211] Batch[5] avg_epoch_loss=4.656645\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:26 INFO 140150847625024] Epoch[211] Batch [5]#011Speed: 260.44 samples/sec#011loss=4.656645\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] Epoch[211] Batch[10] avg_epoch_loss=4.635648\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] Epoch[211] Batch [10]#011Speed: 350.14 samples/sec#011loss=4.610452\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1124.5760917663574, \"sum\": 1124.5760917663574, \"min\": 1124.5760917663574}}, \"EndTime\": 1517703867.034879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703865.898261}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_bb330309-db7b-4ede-9ed6-82b1174e8789-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 60.16182899475098, \"sum\": 60.16182899475098, \"min\": 60.16182899475098}}, \"EndTime\": 1517703867.09527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703867.034946}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] Epoch[212] Batch[0] avg_epoch_loss=4.650313\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] Epoch[212] Batch[5] avg_epoch_loss=4.611823\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:27 INFO 140150847625024] Epoch[212] Batch [5]#011Speed: 326.97 samples/sec#011loss=4.611823\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] Epoch[212] Batch[10] avg_epoch_loss=12.240156\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] Epoch[212] Batch [10]#011Speed: 282.60 samples/sec#011loss=21.394155\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1173.1929779052734, \"sum\": 1173.1929779052734, \"min\": 1173.1929779052734}}, \"EndTime\": 1517703868.280382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703867.095334}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] Epoch[213] Batch[0] avg_epoch_loss=4.532745\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] Epoch[213] Batch[5] avg_epoch_loss=4.618130\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:28 INFO 140150847625024] Epoch[213] Batch [5]#011Speed: 283.67 samples/sec#011loss=4.618130\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:24:29 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1038.6428833007812, \"sum\": 1038.6428833007812, \"min\": 1038.6428833007812}}, \"EndTime\": 1517703869.335904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703868.280446}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:29 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:29 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_af2339c7-53e2-444d-9362-c33f8c161e4f-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.554977416992188, \"sum\": 14.554977416992188, \"min\": 14.554977416992188}}, \"EndTime\": 1517703869.350688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703869.335985}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:29 INFO 140150847625024] Epoch[214] Batch[0] avg_epoch_loss=4.593349\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:29 INFO 140150847625024] Epoch[214] Batch[5] avg_epoch_loss=4.608753\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:29 INFO 140150847625024] Epoch[214] Batch [5]#011Speed: 283.80 samples/sec#011loss=4.608753\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:30 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1049.7410297393799, \"sum\": 1049.7410297393799, \"min\": 1049.7410297393799}}, \"EndTime\": 1517703870.416254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703869.350739}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:30 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:30 INFO 140150847625024] Epoch[215] Batch[0] avg_epoch_loss=4.696805\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] Epoch[215] Batch[5] avg_epoch_loss=4.621088\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] Epoch[215] Batch [5]#011Speed: 283.81 samples/sec#011loss=4.621088\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] Epoch[215] Batch[10] avg_epoch_loss=4.620246\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] Epoch[215] Batch [10]#011Speed: 367.48 samples/sec#011loss=4.619236\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1041.1059856414795, \"sum\": 1041.1059856414795, \"min\": 1041.1059856414795}}, \"EndTime\": 1517703871.469933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703870.416308}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:31 INFO 140150847625024] Epoch[216] Batch[0] avg_epoch_loss=4.658987\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:32 INFO 140150847625024] Epoch[216] Batch[5] avg_epoch_loss=4.596169\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:32 INFO 140150847625024] Epoch[216] Batch [5]#011Speed: 344.97 samples/sec#011loss=4.596169\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:32 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1046.4451313018799, \"sum\": 1046.4451313018799, \"min\": 1046.4451313018799}}, \"EndTime\": 1517703872.534726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703871.47001}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:32 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:32 INFO 140150847625024] Epoch[217] Batch[0] avg_epoch_loss=4.608700\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] Epoch[217] Batch[5] avg_epoch_loss=11.371786\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] Epoch[217] Batch [5]#011Speed: 344.71 samples/sec#011loss=11.371786\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] Epoch[217] Batch[10] avg_epoch_loss=8.288458\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] Epoch[217] Batch [10]#011Speed: 273.54 samples/sec#011loss=4.588463\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1197.0829963684082, \"sum\": 1197.0829963684082, \"min\": 1197.0829963684082}}, \"EndTime\": 1517703873.74531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703872.534778}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:33 INFO 140150847625024] Epoch[218] Batch[0] avg_epoch_loss=4.685526\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] Epoch[218] Batch[5] avg_epoch_loss=4.579150\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] Epoch[218] Batch [5]#011Speed: 272.02 samples/sec#011loss=4.579150\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] Epoch[218] Batch[10] avg_epoch_loss=4.567729\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] Epoch[218] Batch [10]#011Speed: 377.75 samples/sec#011loss=4.554023\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1052.2830486297607, \"sum\": 1052.2830486297607, \"min\": 1052.2830486297607}}, \"EndTime\": 1517703874.809547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703873.745359}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_ac39224b-550c-4b63-b54c-3f6c8f2de4b6-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 51.41305923461914, \"sum\": 51.41305923461914, \"min\": 51.41305923461914}}, \"EndTime\": 1517703874.861177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703874.809612}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:34 INFO 140150847625024] Epoch[219] Batch[0] avg_epoch_loss=4.636938\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:35 INFO 140150847625024] Epoch[219] Batch[5] avg_epoch_loss=4.558408\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:35 INFO 140150847625024] Epoch[219] Batch [5]#011Speed: 347.05 samples/sec#011loss=4.558408\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] Epoch[219] Batch[10] avg_epoch_loss=4.544508\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] Epoch[219] Batch [10]#011Speed: 278.44 samples/sec#011loss=4.527827\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.673978805542, \"sum\": 1132.673978805542, \"min\": 1132.673978805542}}, \"EndTime\": 1517703876.004568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703874.861222}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_f076f5ed-1f84-42b1-ab55-35a5281b3e6e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.878822326660156, \"sum\": 13.878822326660156, \"min\": 13.878822326660156}}, \"EndTime\": 1517703876.018643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703876.004629}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] Epoch[220] Batch[0] avg_epoch_loss=4.644679\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] Epoch[220] Batch[5] avg_epoch_loss=4.605186\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:36 INFO 140150847625024] Epoch[220] Batch [5]#011Speed: 292.79 samples/sec#011loss=4.605186\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] Epoch[220] Batch[10] avg_epoch_loss=4.587844\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] Epoch[220] Batch [10]#011Speed: 379.80 samples/sec#011loss=4.567033\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1021.2540626525879, \"sum\": 1021.2540626525879, \"min\": 1021.2540626525879}}, \"EndTime\": 1517703877.054681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703876.018687}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] Epoch[221] Batch[0] avg_epoch_loss=4.694553\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] Epoch[221] Batch[5] avg_epoch_loss=4.634216\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:37 INFO 140150847625024] Epoch[221] Batch [5]#011Speed: 314.63 samples/sec#011loss=4.634216\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] Epoch[221] Batch[10] avg_epoch_loss=8.233615\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] Epoch[221] Batch [10]#011Speed: 303.12 samples/sec#011loss=12.552895\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1190.1202201843262, \"sum\": 1190.1202201843262, \"min\": 1190.1202201843262}}, \"EndTime\": 1517703878.261161, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703877.054745}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] Epoch[222] Batch[0] avg_epoch_loss=4.597981\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] Epoch[222] Batch[5] avg_epoch_loss=11.206763\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:38 INFO 140150847625024] Epoch[222] Batch [5]#011Speed: 278.63 samples/sec#011loss=11.206763\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:24:39 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1068.4750080108643, \"sum\": 1068.4750080108643, \"min\": 1068.4750080108643}}, \"EndTime\": 1517703879.341885, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703878.261226}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:39 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:39 INFO 140150847625024] Epoch[223] Batch[0] avg_epoch_loss=44.241039\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:39 INFO 140150847625024] Epoch[223] Batch[5] avg_epoch_loss=11.154683\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:39 INFO 140150847625024] Epoch[223] Batch [5]#011Speed: 291.83 samples/sec#011loss=11.154683\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:40 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 997.251033782959, \"sum\": 997.251033782959, \"min\": 997.251033782959}}, \"EndTime\": 1517703880.353528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703879.341965}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:40 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:40 INFO 140150847625024] Epoch[224] Batch[0] avg_epoch_loss=4.532104\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:40 INFO 140150847625024] Epoch[224] Batch[5] avg_epoch_loss=4.536632\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:40 INFO 140150847625024] Epoch[224] Batch [5]#011Speed: 290.54 samples/sec#011loss=4.536632\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:41 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1064.087152481079, \"sum\": 1064.087152481079, \"min\": 1064.087152481079}}, \"EndTime\": 1517703881.432112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703880.353604}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:41 INFO 140150847625024] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:41 INFO 140150847625024] Epoch[225] Batch[0] avg_epoch_loss=4.541878\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:42 INFO 140150847625024] Epoch[225] Batch[5] avg_epoch_loss=4.548914\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:42 INFO 140150847625024] Epoch[225] Batch [5]#011Speed: 279.15 samples/sec#011loss=4.548914\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:42 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1085.5929851531982, \"sum\": 1085.5929851531982, \"min\": 1085.5929851531982}}, \"EndTime\": 1517703882.532022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703881.432189}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:42 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:42 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_18e2875b-b8cf-418a-98e1-111019b747bf-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.519929885864258, \"sum\": 14.519929885864258, \"min\": 14.519929885864258}}, \"EndTime\": 1517703882.54679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703882.5321}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:42 INFO 140150847625024] Epoch[226] Batch[0] avg_epoch_loss=4.564768\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:43 INFO 140150847625024] Epoch[226] Batch[5] avg_epoch_loss=4.519987\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:43 INFO 140150847625024] Epoch[226] Batch [5]#011Speed: 246.53 samples/sec#011loss=4.519987\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:43 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1086.7600440979004, \"sum\": 1086.7600440979004, \"min\": 1086.7600440979004}}, \"EndTime\": 1517703883.648702, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703882.546841}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:43 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:43 INFO 140150847625024] Epoch[227] Batch[0] avg_epoch_loss=4.501367\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] Epoch[227] Batch[5] avg_epoch_loss=4.506190\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] Epoch[227] Batch [5]#011Speed: 296.06 samples/sec#011loss=4.506190\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] Epoch[227] Batch[10] avg_epoch_loss=4.497787\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] Epoch[227] Batch [10]#011Speed: 353.98 samples/sec#011loss=4.487703\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1047.4820137023926, \"sum\": 1047.4820137023926, \"min\": 1047.4820137023926}}, \"EndTime\": 1517703884.711337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703883.648777}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_896bff4c-4da0-4a6a-a82e-7d14e1289e13-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 54.51393127441406, \"sum\": 54.51393127441406, \"min\": 54.51393127441406}}, \"EndTime\": 1517703884.7661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703884.711415}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:44 INFO 140150847625024] Epoch[228] Batch[0] avg_epoch_loss=4.633043\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:45 INFO 140150847625024] Epoch[228] Batch[5] avg_epoch_loss=4.535451\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:45 INFO 140150847625024] Epoch[228] Batch [5]#011Speed: 323.49 samples/sec#011loss=4.535451\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:45 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1004.6260356903076, \"sum\": 1004.6260356903076, \"min\": 1004.6260356903076}}, \"EndTime\": 1517703885.786092, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703884.766149}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:45 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:45 INFO 140150847625024] Epoch[229] Batch[0] avg_epoch_loss=4.638070\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:46 INFO 140150847625024] Epoch[229] Batch[5] avg_epoch_loss=4.541740\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:46 INFO 140150847625024] Epoch[229] Batch [5]#011Speed: 339.59 samples/sec#011loss=4.541740\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:46 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 978.4069061279297, \"sum\": 978.4069061279297, \"min\": 978.4069061279297}}, \"EndTime\": 1517703886.780558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703885.786167}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:46 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:46 INFO 140150847625024] Epoch[230] Batch[0] avg_epoch_loss=4.598656\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:47 INFO 140150847625024] Epoch[230] Batch[5] avg_epoch_loss=4.538326\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:47 INFO 140150847625024] Epoch[230] Batch [5]#011Speed: 337.71 samples/sec#011loss=4.538326\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:47 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1020.8859443664551, \"sum\": 1020.8859443664551, \"min\": 1020.8859443664551}}, \"EndTime\": 1517703887.814824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703886.780607}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:47 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:47 INFO 140150847625024] Epoch[231] Batch[0] avg_epoch_loss=4.573449\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:48 INFO 140150847625024] Epoch[231] Batch[5] avg_epoch_loss=4.485083\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:48 INFO 140150847625024] Epoch[231] Batch [5]#011Speed: 355.90 samples/sec#011loss=4.485083\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:48 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 969.3138599395752, \"sum\": 969.3138599395752, \"min\": 969.3138599395752}}, \"EndTime\": 1517703888.799819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703887.814891}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:48 INFO 140150847625024] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:48 INFO 140150847625024] Epoch[232] Batch[0] avg_epoch_loss=4.537525\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:24:49 INFO 140150847625024] Epoch[232] Batch[5] avg_epoch_loss=4.495730\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:49 INFO 140150847625024] Epoch[232] Batch [5]#011Speed: 308.34 samples/sec#011loss=4.495730\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:49 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1018.5708999633789, \"sum\": 1018.5708999633789, \"min\": 1018.5708999633789}}, \"EndTime\": 1517703889.831333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703888.799898}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:49 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:49 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_b80ca4b8-08cb-4aec-b274-1cb24ff1a49f-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 51.9871711730957, \"sum\": 51.9871711730957, \"min\": 51.9871711730957}}, \"EndTime\": 1517703889.883492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703889.831381}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:49 INFO 140150847625024] Epoch[233] Batch[0] avg_epoch_loss=4.479679\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:50 INFO 140150847625024] Epoch[233] Batch[5] avg_epoch_loss=4.495497\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:50 INFO 140150847625024] Epoch[233] Batch [5]#011Speed: 357.30 samples/sec#011loss=4.495497\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:50 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 956.6349983215332, \"sum\": 956.6349983215332, \"min\": 956.6349983215332}}, \"EndTime\": 1517703890.851009, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703889.883529}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:50 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:51 INFO 140150847625024] Epoch[234] Batch[0] avg_epoch_loss=4.530718\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:51 INFO 140150847625024] Epoch[234] Batch[5] avg_epoch_loss=4.461277\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:51 INFO 140150847625024] Epoch[234] Batch [5]#011Speed: 334.69 samples/sec#011loss=4.461277\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:51 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1016.2959098815918, \"sum\": 1016.2959098815918, \"min\": 1016.2959098815918}}, \"EndTime\": 1517703891.883135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703890.851074}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:51 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:51 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_8cd6ffa6-e7fd-426f-9c2b-aee99feb0b91-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.8458309173584, \"sum\": 57.8458309173584, \"min\": 57.8458309173584}}, \"EndTime\": 1517703891.94123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703891.883202}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:52 INFO 140150847625024] Epoch[235] Batch[0] avg_epoch_loss=4.596759\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:52 INFO 140150847625024] Epoch[235] Batch[5] avg_epoch_loss=4.488438\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:52 INFO 140150847625024] Epoch[235] Batch [5]#011Speed: 331.61 samples/sec#011loss=4.488438\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:52 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 978.8858890533447, \"sum\": 978.8858890533447, \"min\": 978.8858890533447}}, \"EndTime\": 1517703892.932264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703891.941274}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:52 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:53 INFO 140150847625024] Epoch[236] Batch[0] avg_epoch_loss=4.607832\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:53 INFO 140150847625024] Epoch[236] Batch[5] avg_epoch_loss=4.462958\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:53 INFO 140150847625024] Epoch[236] Batch [5]#011Speed: 309.58 samples/sec#011loss=4.462958\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:53 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1027.2541046142578, \"sum\": 1027.2541046142578, \"min\": 1027.2541046142578}}, \"EndTime\": 1517703893.97601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703892.932399}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:53 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:54 INFO 140150847625024] Epoch[237] Batch[0] avg_epoch_loss=4.536289\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:54 INFO 140150847625024] Epoch[237] Batch[5] avg_epoch_loss=4.489363\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:54 INFO 140150847625024] Epoch[237] Batch [5]#011Speed: 343.72 samples/sec#011loss=4.489363\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:55 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1036.6880893707275, \"sum\": 1036.6880893707275, \"min\": 1036.6880893707275}}, \"EndTime\": 1517703895.025342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703893.976059}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:55 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:55 INFO 140150847625024] Epoch[238] Batch[0] avg_epoch_loss=4.479807\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:55 INFO 140150847625024] Epoch[238] Batch[5] avg_epoch_loss=4.424263\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:55 INFO 140150847625024] Epoch[238] Batch [5]#011Speed: 316.58 samples/sec#011loss=4.424263\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] Epoch[238] Batch[10] avg_epoch_loss=4.428022\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] Epoch[238] Batch [10]#011Speed: 287.48 samples/sec#011loss=4.432533\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1224.6959209442139, \"sum\": 1224.6959209442139, \"min\": 1224.6959209442139}}, \"EndTime\": 1517703896.269808, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703895.02542}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_088866b4-3dfc-43df-86b7-8d2a0e0ac610-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.27204704284668, \"sum\": 13.27204704284668, \"min\": 13.27204704284668}}, \"EndTime\": 1517703896.283286, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703896.269859}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] Epoch[239] Batch[0] avg_epoch_loss=4.459585\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] Epoch[239] Batch[5] avg_epoch_loss=4.411473\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:56 INFO 140150847625024] Epoch[239] Batch [5]#011Speed: 288.29 samples/sec#011loss=4.411473\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] Epoch[239] Batch[10] avg_epoch_loss=7.934491\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] Epoch[239] Batch [10]#011Speed: 379.75 samples/sec#011loss=12.162113\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1016.5958404541016, \"sum\": 1016.5958404541016, \"min\": 1016.5958404541016}}, \"EndTime\": 1517703897.312235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703896.283328}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] Epoch[240] Batch[0] avg_epoch_loss=4.442424\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] Epoch[240] Batch[5] avg_epoch_loss=4.444647\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:57 INFO 140150847625024] Epoch[240] Batch [5]#011Speed: 355.73 samples/sec#011loss=4.444647\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:58 INFO 140150847625024] Epoch[240] Batch[10] avg_epoch_loss=4.423797\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:58 INFO 140150847625024] Epoch[240] Batch [10]#011Speed: 268.52 samples/sec#011loss=4.398777\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:58 INFO 140150847625024] processed a total of 384 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1217.9210186004639, \"sum\": 1217.9210186004639, \"min\": 1217.9210186004639}}, \"EndTime\": 1517703898.546062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703897.312297}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:58 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:58 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_fee72164-3a64-433b-a144-4fdb947386f9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 60.66107749938965, \"sum\": 60.66107749938965, \"min\": 60.66107749938965}}, \"EndTime\": 1517703898.606998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703898.546148}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:58 INFO 140150847625024] Epoch[241] Batch[0] avg_epoch_loss=4.433224\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/04/2018 00:24:59 INFO 140150847625024] Epoch[241] Batch[5] avg_epoch_loss=4.378894\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:59 INFO 140150847625024] Epoch[241] Batch [5]#011Speed: 361.16 samples/sec#011loss=4.378894\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:59 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 962.0480537414551, \"sum\": 962.0480537414551, \"min\": 962.0480537414551}}, \"EndTime\": 1517703899.580714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703898.607053}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:59 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:59 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_68420717-6702-4f79-921c-079873ae4e1b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.66691398620605, \"sum\": 65.66691398620605, \"min\": 65.66691398620605}}, \"EndTime\": 1517703899.646578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703899.580767}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:24:59 INFO 140150847625024] Epoch[242] Batch[0] avg_epoch_loss=4.564875\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] Epoch[242] Batch[5] avg_epoch_loss=4.392187\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] Epoch[242] Batch [5]#011Speed: 333.92 samples/sec#011loss=4.392187\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] Epoch[242] Batch[10] avg_epoch_loss=4.406557\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] Epoch[242] Batch [10]#011Speed: 279.18 samples/sec#011loss=4.423802\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1171.1921691894531, \"sum\": 1171.1921691894531, \"min\": 1171.1921691894531}}, \"EndTime\": 1517703900.830327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703899.646629}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:00 INFO 140150847625024] Epoch[243] Batch[0] avg_epoch_loss=4.488060\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:01 INFO 140150847625024] Epoch[243] Batch[5] avg_epoch_loss=4.426445\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:01 INFO 140150847625024] Epoch[243] Batch [5]#011Speed: 266.37 samples/sec#011loss=4.426445\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:01 INFO 140150847625024] Epoch[243] Batch[10] avg_epoch_loss=4.417588\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:01 INFO 140150847625024] Epoch[243] Batch [10]#011Speed: 349.12 samples/sec#011loss=4.406960\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:01 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1112.2829914093018, \"sum\": 1112.2829914093018, \"min\": 1112.2829914093018}}, \"EndTime\": 1517703901.954776, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703900.830386}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:01 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:02 INFO 140150847625024] Epoch[244] Batch[0] avg_epoch_loss=4.390903\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:02 INFO 140150847625024] Epoch[244] Batch[5] avg_epoch_loss=4.413080\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:02 INFO 140150847625024] Epoch[244] Batch [5]#011Speed: 319.21 samples/sec#011loss=4.413080\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] Epoch[244] Batch[10] avg_epoch_loss=4.394000\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] Epoch[244] Batch [10]#011Speed: 301.21 samples/sec#011loss=4.371105\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1170.3548431396484, \"sum\": 1170.3548431396484, \"min\": 1170.3548431396484}}, \"EndTime\": 1517703903.141169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703901.954835}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_5f10ea43-251b-4d33-9b69-14a6ae6269df-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.68205451965332, \"sum\": 14.68205451965332, \"min\": 14.68205451965332}}, \"EndTime\": 1517703903.156088, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703903.141245}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] Epoch[245] Batch[0] avg_epoch_loss=4.507121\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] Epoch[245] Batch[5] avg_epoch_loss=4.477141\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:03 INFO 140150847625024] Epoch[245] Batch [5]#011Speed: 289.49 samples/sec#011loss=4.477141\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] Epoch[245] Batch[10] avg_epoch_loss=4.463974\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] Epoch[245] Batch [10]#011Speed: 368.06 samples/sec#011loss=4.448174\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1030.2069187164307, \"sum\": 1030.2069187164307, \"min\": 1030.2069187164307}}, \"EndTime\": 1517703904.20123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703903.156135}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] Epoch[246] Batch[0] avg_epoch_loss=4.300804\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] Epoch[246] Batch[5] avg_epoch_loss=4.394516\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:04 INFO 140150847625024] Epoch[246] Batch [5]#011Speed: 322.69 samples/sec#011loss=4.394516\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:05 INFO 140150847625024] Epoch[246] Batch[10] avg_epoch_loss=4.364270\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:05 INFO 140150847625024] Epoch[246] Batch [10]#011Speed: 270.85 samples/sec#011loss=4.327974\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:05 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1227.6611328125, \"sum\": 1227.6611328125, \"min\": 1227.6611328125}}, \"EndTime\": 1517703905.44399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703904.201303}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:05 INFO 140150847625024] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:05 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/state_d81c81aa-c140-4a29-8bd8-b91b47a06cb5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 14.64390754699707, \"sum\": 14.64390754699707, \"min\": 14.64390754699707}}, \"EndTime\": 1517703905.458869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703905.444063}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:05 INFO 140150847625024] Epoch[247] Batch[0] avg_epoch_loss=4.511713\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:06 INFO 140150847625024] Epoch[247] Batch[5] avg_epoch_loss=17.575284\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:06 INFO 140150847625024] Epoch[247] Batch [5]#011Speed: 281.98 samples/sec#011loss=17.575284\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:06 INFO 140150847625024] processed a total of 320 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1028.6080837249756, \"sum\": 1028.6080837249756, \"min\": 1028.6080837249756}}, \"EndTime\": 1517703906.502195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703905.458916}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:06 INFO 140150847625024] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:06 INFO 140150847625024] Epoch[248] Batch[0] avg_epoch_loss=42.837452\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] Epoch[248] Batch[5] avg_epoch_loss=10.808427\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] Epoch[248] Batch [5]#011Speed: 284.68 samples/sec#011loss=10.808427\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] Epoch[248] Batch[10] avg_epoch_loss=11.351493\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] Epoch[248] Batch [10]#011Speed: 340.29 samples/sec#011loss=12.003173\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1073.0609893798828, \"sum\": 1073.0609893798828, \"min\": 1073.0609893798828}}, \"EndTime\": 1517703907.589825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703906.502254}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:07 INFO 140150847625024] Epoch[249] Batch[0] avg_epoch_loss=4.337799\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] Epoch[249] Batch[5] avg_epoch_loss=4.388665\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] Epoch[249] Batch [5]#011Speed: 340.61 samples/sec#011loss=4.388665\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] Epoch[249] Batch[10] avg_epoch_loss=4.364975\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] Epoch[249] Batch [10]#011Speed: 297.42 samples/sec#011loss=4.336547\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] processed a total of 352 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.951021194458, \"sum\": 1132.951021194458, \"min\": 1132.951021194458}}, \"EndTime\": 1517703908.739808, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703907.589891}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] Loading parameters from best epoch (246)\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 5.9490203857421875, \"sum\": 5.9490203857421875, \"min\": 5.9490203857421875}}, \"EndTime\": 1517703908.745945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703908.739862}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:08 INFO 140150847625024] Final loss: 4.36426990682 (occured at epoch 246)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 791.3470268249512, \"sum\": 791.3470268249512, \"min\": 791.3470268249512}}, \"EndTime\": 1517703909.53746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703908.745986}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:10 INFO 140150847625024] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1319.969892501831, \"sum\": 1319.969892501831, \"min\": 1319.969892501831}}, \"EndTime\": 1517703910.06606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703909.537509}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:10 INFO 140150847625024] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:10 INFO 140150847625024] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 93.0781364440918, \"sum\": 93.0781364440918, \"min\": 93.0781364440918}}, \"EndTime\": 1517703910.159222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703910.066108}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:10 INFO 140150847625024] Rebinding module with batch size 32 \u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:10 INFO 140150847625024] Executor bound\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 667.834997177124, \"sum\": 667.834997177124, \"min\": 667.834997177124}}, \"EndTime\": 1517703910.828038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703910.159267}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 934.7450733184814, \"sum\": 934.7450733184814, \"min\": 934.7450733184814}}, \"EndTime\": 1517703911.094936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703910.828101}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:11 INFO 140150847625024] #test_score (algo-1, wQuantileLoss[0.5]): 0.105763\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:11 INFO 140150847625024] #test_score (algo-1, wQuantileLoss[0.9]): 0.0445193\u001b[0m\n",
      "\u001b[31m[02/04/2018 00:25:11 INFO 140150847625024] #test_score (algo-1, RMSE): 14.7199913846\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 279284.3089103699, \"sum\": 279284.3089103699, \"min\": 279284.3089103699}, \"setuptime\": {\"count\": 1, \"max\": 12.23301887512207, \"sum\": 12.23301887512207, \"min\": 12.23301887512207}}, \"EndTime\": 1517703911.236491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1517703911.095007}\n",
      "\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bp-job-2018-02-04-00-14-40-208'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: bp-job-2018-02-04-00-14-40-208\n",
      "INFO:sagemaker:Creating endpoint-config with name bp-job-2018-02-04-00-14-40-208\n",
      "INFO:sagemaker:Creating endpoint with name bp-job-2018-02-04-00-14-40-208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.RealTimePredictor(\n",
    "    endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    content_type=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": [{\"start\": \"2017-02-01 08:00:00\", \"target\": [134, 138, 138, 124, 140, 134, 135, 141, 122, 137, 136, 130, 145, 121, 118, 118, 134, 116, 147, 112, 119, 146, 138, 142, 149, 115, 119, 133, 140, 149, 140, 136, 111, 117, 140, 145, 124, 132, 132, 141, 149, 128, 134, 132, 129, 119, 148, 119, 126, 121, 116, 119, 128, 127, 149, 123, 135, 147, 134, 122, 135, 127, 113, 130, 136, 145, 130, 146, 125, 123, 128, 125, 138, 119, 137, 143, 138, 127, 115, 123, 117, 135, 134, 132, 111, 111, 150, 129, 120, 117, 110, 113, 138, 141, 132, 132, 149, 147, 115, 146, 138, 129, 133, 129, 139, 111, 147, 124, 124, 122, 138, 141, 135, 125, 130, 138, 114, 128, 131, 136, 140, 113, 149, 126, 148, 149, 146, 146, 117, 143, 129, 142, 145, 117, 115, 144, 113, 146, 146, 118, 124, 116, 129, 124, 146, 133, 131, 132, 148, 118, 144, 122, 136, 111, 123, 119, 125, 123, 119, 149, 127, 128, 114, 128, 146, 144, 135, 113, 136, 146, 117, 135, 150, 119, 116, 143, 149, 147, 140, 117, 114, 120, 115, 118, 114, 135, 114, 140, 117, 118, 117, 119, 124, 130, 141, 130, 143, 144, 116, 112, 144, 136, 128, 123, 120, 118, 130, 121, 138, 113, 123, 149, 136, 130, 132, 118, 124, 148, 129, 117, 114, 131, 115, 148, 131, 126, 129, 138, 144, 120, 147, 148, 146, 112, 114, 128, 147, 115, 146, 119, 148, 139, 134, 132, 133, 148, 130, 131, 119, 119, 137, 117, 147, 136, 116, 137, 135, 122, 123, 126, 113, 144, 124, 121, 120, 116, 130, 121, 148, 147, 122, 120, 112, 133, 129, 149, 127, 142, 140, 145, 121, 142, 125, 143, 149, 133, 138, 120, 142, 121, 127, 126, 115, 129, 115, 134, 138, 143, 118, 149, 139, 138, 130, 117, 133, 133, 122, 141, 119, 115, 134, 137, 128, 135, 130, 147, 140, 124, 123, 128, 118, 127, 130, 113, 118, 135, 110, 147, 148, 112, 146, 134, 136, 130, 120, 114, 133, 139, 148, 128, 121, 131, 149, 128, 141, 134, 124, 125, 148, 123, 134, 133, 143, 138, 118, 132, 146, 113, 121, 124, 150, 122, 127, 147, 116, 144, 149, 123, 145, 141, 116, 110, 121, 149, 149, 126, 138, 125, 140, 126, 138, 116, 147, 122, 123, 122, 141, 128, 131, 114, 150, 131, 147, 121, 133, 112, 119, 147, 111, 112, 145, 119, 111, 135, 132, 136, 144, 111, 144, 136, 116, 146, 147, 146, 122, 144, 119, 123, 143, 116, 137, 145, 119, 139, 117, 150, 124, 145, 146, 134, 146, 144, 128, 122, 111, 135, 140, 112, 146, 140, 112, 113, 135, 134, 146, 149, 118, 131, 121, 117, 119, 136, 120, 135, 113, 130, 130, 150, 130, 129, 110, 113, 131, 115, 127, 120, 135, 139, 129, 111, 116, 132, 112, 126, 145, 112, 137, 121, 124, 126, 122, 128, 117, 121, 146, 138, 144, 114, 123, 118, 115, 137, 135, 139, 148, 138, 136, 124, 130, 136, 123, 126, 117, 145, 117, 139, 123, 144, 126, 150, 149, 124, 149, 118, 135, 124, 130, 142, 146, 137, 145, 117, 122, 118, 126, 126, 127, 126, 140, 146, 110, 110, 138, 141, 128, 124, 120, 137, 137, 124, 123, 137, 115, 113, 139, 136, 143, 143, 139, 149, 143, 141, 131, 130, 128, 111, 141, 116, 146, 133, 121, 113, 130, 136, 137, 140, 139, 143, 146, 139, 118, 126, 113, 129, 124, 123, 130, 131, 144, 142, 122, 137, 134, 111, 149, 117, 149, 134, 131, 129, 145, 136, 131, 143, 121, 110, 129, 114, 128, 112, 147, 112, 143, 133, 145, 138, 148, 149, 128, 119, 119, 117, 127, 116, 117, 122, 135, 145, 149, 119, 132, 124, 140, 110, 118, 126, 134, 148, 116, 119, 114, 123, 118, 114, 143, 148, 128, 124, 132, 145, 133, 132, 119, 134, 143, 133, 110, 126, 120, 137, 148, 114, 124, 149, 126, 121, 140, 122, 149, 147, 143, 142, 143, 136, 132, 126, 112, 139, 144, 122, 123, 129, 147, 120, 112, 129, 112, 132, 131, 124, 116, 142, 132, 139, 146, 149, 150, 125, 147, 112, 147, 145, 114, 116, 135, 149, 112, 114, 143, 134, 119, 138, 147, 115, 143, 119, 116, 120, 147, 117, 120, 114, 132, 116, 115, 141, 115, 121, 134, 148, 131, 114, 115, 138, 148, 127, 121, 144, 135, 112, 127, 149, 149, 117, 116, 149, 140, 111, 140, 118, 112, 118, 149, 144, 131, 148, 122, 137, 139, 111, 138, 117, 116, 121, 125, 140, 130, 116, 125, 121, 130, 118, 129, 111, 126, 118, 145, 115, 128, 120, 124, 138, 136, 143, 133, 118, 132, 127, 119, 140, 128, 147, 112, 133, 142, 131, 136, 146, 145, 135, 128, 130, 144, 122, 138, 150, 121, 139, 139, 123, 136, 123, 132, 149, 140, 119, 133, 149, 149, 118, 142, 148, 119, 129, 136, 146, 134, 114, 117, 114, 113, 128, 127, 147, 129, 128, 111, 116, 148, 141, 137, 144, 135, 131, 130, 148, 132, 147, 111, 141, 121, 137, 124, 129, 119, 122, 123, 132, 148, 143, 131, 145, 122, 126, 128, 148, 117, 145, 135, 110, 149, 140, 142, 111, 111, 139, 142, 119, 126, 139, 122, 150, 124, 123, 113, 118, 139, 122, 141, 136, 144, 143, 135, 135, 124, 140, 112, 146, 131, 112, 124, 116, 137, 123, 150, 110, 144, 127, 119, 148, 131, 141, 131, 135, 149, 141, 130, 143, 146, 116, 150, 141, 126, 132, 111, 114, 117, 130, 124, 120, 125, 140, 144, 143, 144, 150, 141, 133, 144, 139, 138, 132, 114, 139, 134, 120, 120, 139, 141, 118, 137, 132, 129, 119, 147, 110, 118, 115, 110, 126, 126, 132, 137, 146, 131, 129, 139, 125, 149, 134, 146, 126, 139, 134, 133, 111, 133, 113, 138, 119, 136, 135, 122, 138, 122, 134, 124, 133, 111, 137, 128, 115, 118, 128, 118, 115, 119, 148, 113, 124, 121, 120, 119, 145, 146, 135, 139, 120, 125, 117, 145, 123, 148, 127, 130, 117, 134, 120, 130, 123, 147, 114, 142, 146, 136, 112, 132, 130, 138, 139, 138, 139, 121, 148, 138, 141, 122, 147, 143, 115, 125, 139, 126, 147, 146, 131, 127, 115, 129, 149, 138, 113, 135, 142, 143, 139, 144, 134, 134, 131, 143, 116, 115, 148, 144, 117, 113, 135, 120, 117, 147, 140, 116, 127, 138, 136, 147, 127, 132, 129, 128, 132, 122, 123, 128, 149, 134, 132, 139, 149, 139, 149, 113, 137, 125, 116, 110, 128, 121, 111, 132, 130, 141, 139, 121, 118, 120, 119, 117, 118, 143, 112, 140, 113, 117, 116, 112, 144, 135, 138, 147, 122, 142, 140, 146, 146, 113, 123, 136, 142, 124, 132, 116, 124, 147, 114, 138, 122, 138, 118, 129, 140, 149, 121, 126, 139, 114, 133, 144, 144, 121, 139, 123, 141, 114, 130, 138, 116, 120, 135, 132, 130, 119, 111, 129, 122, 113, 111, 148, 120, 114, 135, 143, 142, 115, 115, 111, 120, 146, 131, 119, 124, 135, 146, 142, 120, 114, 122, 147, 145, 144, 141, 127, 139, 129, 122, 125, 125, 132, 114, 142, 115, 114, 138, 126, 141, 112, 133, 110, 146, 119, 119, 126, 115, 116, 135, 147, 127, 127, 133, 135, 117, 133, 119, 149, 136, 140, 128, 119, 136, 135, 121, 128, 112, 112, 131, 125, 132, 120, 148, 115, 147, 120, 147, 130, 140, 133, 122, 141, 116, 148, 113, 120, 124, 144, 115, 123, 115, 127, 136, 146, 146, 138, 122, 146, 124, 128, 113, 112, 116, 141, 137, 122, 148, 116, 135, 113, 127, 131, 145, 130, 118, 118, 127, 138, 133, 135, 145, 113, 112, 148, 119, 127, 149, 137, 143, 126, 115, 118, 140, 132, 132, 143, 145, 145, 118, 131, 122, 149, 116, 145, 116, 120, 133, 139, 122, 137, 149, 116, 130, 116, 145, 113, 128, 113, 132, 142, 123, 123, 135, 140, 112, 140, 110, 135, 144, 129, 145, 143, 123, 118, 127, 125, 124, 137, 129, 137, 120, 145, 116, 149, 116, 114, 110, 133, 122, 148, 143, 113, 113, 143, 142, 137, 145, 135, 143, 145, 145, 116, 117, 131, 130, 119, 115, 120, 149, 147, 119, 135, 130, 149, 138, 123, 135, 142, 117, 147, 128, 121, 133, 121, 131, 144, 139, 111, 148, 120, 124, 128, 141, 143, 114, 132, 124, 122, 148, 126, 146, 112, 118, 149, 125, 121, 128, 122, 111, 143, 124, 138, 131, 142, 139, 133, 123, 119, 137, 143, 148, 117, 112, 134, 112, 123, 134, 134, 119, 129, 136, 141, 116, 135, 142, 144, 138, 147, 146, 134, 135, 124, 146]}], \"configuration\": {\"output_types\": [\"samples\"], \"num_samples\": 1}}\n"
     ]
    }
   ],
   "source": [
    "q1 = '0.1'         # compute p10 quantile\n",
    "q2 = '0.9'         # compute p90 quantile\n",
    "num_samples = 1  # predict 6 sample series\n",
    "    \n",
    "s = {\"start\": \"2017-02-01 08:00:00\", \"target\": bp_sistolic}\n",
    "series = []\n",
    "series.append(s)\n",
    "\n",
    "configuration = {\n",
    "        \"output_types\": [\"samples\"],\n",
    "        \"num_samples\": num_samples}\n",
    "http_data = {\n",
    "        \"instances\": series, \n",
    "        \"configuration\": configuration\n",
    "}\n",
    "http_data = json.dumps(http_data)\n",
    "print(http_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"predictions\":[{\"samples\":[[125.4389038086,115.7813720703,128.1891784668,125.4847869873,102.7653808594,98.6500930786,133.0986328125,95.2591247559,136.8067779541,112.9621810913,117.986000061,99.4025115967,114.7673110962,131.3999023438,140.259475708,167.5045013428,191.4559326172,168.1932525635,125.5912628174,83.216293335,122.5363845825,104.8993148804,96.9972686768,119.0280456543]]}]}'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predictor.predict(http_data)\n",
    "result.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
